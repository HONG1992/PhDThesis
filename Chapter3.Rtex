\clearpage


%%begin.rcode settings, echo = FALSE, cache = FALSE, message = FALSE, results = 'hide', eval = TRUE


##################################
### Run web scraping?          ###
##################################

# There's some slow webscrapping functions. Run them?
runPubmedScrape <- FALSE
runScholarScrape <- FALSE
runFstScrape <- FALSE


# Run slow bootstrapping?
subBoots <- FALSE
fstBoots <- TRUE
batclocksBoots <- FALSE

# There are figures created in the data analysis which are not in the final chapter document.
#   If TRUE, they will be included in the output.
#   Use 'hide' to remove them.
extraFigs <- 'hide'

#knitr options
opts_chunk$set(cache.path = '.Ch3Cache/')
source('misc/KnitrOptions.R')

# ggplot2 theme.
source('misc/theme_tcdl.R')


# Choose the number of cores to use
nCores <- 7

%%end.rcode


%%begin.rcode libs, cache = FALSE, result = FALSE

# Data handling
library(dplyr)
library(broom)
library(readxl)
library(sqldf)
library(reshape2)

# phylogenetic regression
library(ape)
library(caper)
library(phytools)
library(nlme)
library(qpcR)
library(car)

# Plotting
library(ggplot2)
library(dotwhisker)
library(ggtree)
library(palettetown)
library(ggthemes)
library(GGally)


# Web scraping.
library(rvest)

# For synonym list
library(taxize)

# Spatial analysis
library(maptools)
library(geosphere)

# Parllel computation
library(parallel)

%%end.rcode

\section{Abstract}


\tmpsection{One or two sentences providing a basic introduction to the field}
% comprehensible to a scientist in any discipline.
\lettr{I}t is still unclear what factors determine the number of pathogens a wild species carries.
But once understood, these factors could provide a way to prioritise surveillance of wild populations for zoonotic disease.


\tmpsection{Two to three sentences of more detailed background}
% comprehensible to scientists in related disciplines.

% Theory led.
% 

The pattern of contacts between individuals (i.e. population structure) has long been known to strongly affect epidemic processes.
Theory suggests that population structure can promote pathogen richness while the ecological literature generally assumes it will decrease richness.
It is still unclear how important population structure is in controlling pathogen richness in wild populations.
Previous studies have had contradictory results and the different measures of population structure have different shortcomings.


\tmpsection{One sentence clearly stating the general problem (the gap)}
% being addressed by this particular study.

Here I use comparative data to test whether population structure influences pathogen richness in bats.
I use two measures of population structure: a novel measure, number of subspecies, and a more careful application of genetic measures which have been used previously.

\tmpsection{One sentence summarising the main result}
%  (with the words “here we show” or their equivalent).

I find that both of these measures are associated with pathogen richness 


\tmpsection{Two or three sentences explaining what the main result reveals in direct comparison to what was thought to be the case previously}
% or how the main result adds to previous knowledge

Previous studies have conflicting results on the direction and importance of a relationship between population structure and pathogen diversity.
Here, using a larger dataset than previous studies, I find that both measures of populations structure suggest that population structure may increase pathogen diversity.

\tmpsection{One or two sentences to put the results into a more general context.}

Given the conflicting results in the literature, it seems that the relationship between population structure and pathogen diversity might be sensitive to the specific dataset and measure of populationn structure.
The use of a larger dataset and multiple measures of population structure therefore provide stronger evidence that population structure causes high pathogen diversity.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\section{Introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{General Intro}




\subsection{Specific Intro}



\subsection{Theoretical background}



\subsection{Previous Studies}

Three studies have used comparative data to test for an association between population structure and viral richness.
A study on 15 African bats found a positive relationship between distribution fragmentation and viral richness \cite{maganga2014bat} while a study on 20 South-East Asian bats found the opposite relationship \cite{gay2014parasite}. 
A global study on 33 bats found a positive relationship between $F_{ST}$ --- a measure of genetic structure --- and viral richness \cite{turmelle2009correlates}. 
However, this study included measures using mtDNA which only measures female dispersal which may haved biased the results many bat species show female philopatry \cite{kerth2002extreme, hulva2010mechanisms}.
Furthermore, this study used measures of $F_{ST}$ irrespective of the study scale with studies covering from tens \cite{mccracken1981social} to thousands \cite{petit1999male} of kilometers.
As isolation by distance has been shown in a number of bat species \cite{burland1999population, hulva2010mechanisms, o2015genetic, vonhof2015range} this could bias results further.
Finally, when a global $F_{ST}$ value is not given they use the mean of all pairwise $F_{ST}$ between sites.
It is not clear that this is correct as from global $F_{ST}$ we expect migration rates of $M = \frac{1-F_{ST}}{8F_{ST}}$ while from $F_{ST}$ between pairs of populations we expect migration rates of $M = \frac{1-F_{ST}}{16 F_{ST}}$ where $M$ is the absolute number of diploid inviduals dispersing per generation \cite{slatkin1995measure}.
As it is in fact the movement of individuals that is epidemiologically relavent, using these studies is probably not correct without attempting to correct for these difference.




\subsection{Choice of measure of population structure}
  
\tmpsection{Direct dispersal measurements}

The direct study of bat dispersal is difficult due to their size, lack of identifying marks and potential for long distance travel --- in particular knowing how far individuals disperse is incredibly difficult.


\tmpsection{Genetic measures}

Both genetic measures and existence of subspecies differ 

\tmpsection{Number of Subspecies}

\tmpsection{Measures from range}







\subsection{The gap}




\subsection{What I did}




\subsection{What I found}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\clearpage
\section{Methods}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%begin.rcode parameters
# Define some parameters.
#   This is useful at the top so that it can go in text.

# How many bootstraps for model selection NULL variable
nBoots <- 50


# What proportion of a species range should be covered for an Fst study to count as valid.
rangeUseable <- 0.20



%%end.rcode

%%begin.rcode luis2013virusRead

#read in luis2013virus data
virus2 <- read.csv('data/Chapter3/luis2013comparison.csv', stringsAsFactors = FALSE)


virus2$binomial <- paste(virus2$host.genus, virus2$host.species)


# From methods
#Many viruses were not identified to species level or their identified species was not in the ICTV virus taxonomy \cite{ICTV}.
#I counted a virus if it was the only virus, for that host species, in the lowest taxonomic level identified in the ICTV taxonomy.
#That is, if a host carries an unknown Paramyxoviridae virus, then it must carry at least one Paramyxoviridae virus.
#If a host carries an unknown Paramyxoviridae virus and a known Paramyxoviridae virus, then it is hard to confirm that the unknown virus is not another record of the known virus.
#In this case, this would be counted as one virus species.

# This has been implemented manually and indicated in the column `remove`

virus2 <- virus2[!virus2$remove, ]

%%end.rcode


%%begin.rcode wilsonReaderTaxonomyRead, fig.show = extraFigs, fig.cap = 'Histogram of number of subspecies'

##################################################################
### Subspecies vs Viruses analysis.                            ###
##################################################################


# Read in the wilson Reader Taxonomy and use it to calculate the number of subspecies each bat species has.

tax <- read.csv('data/Chapter3/msw3-all.csv', stringsAsFactors = FALSE)

chir <- tax %>%
          filter(Order == 'CHIROPTERA')

# Save some memory.
rm(tax)

# Count the number of subspecies each bat species has.
subs <- sqldf('
  SELECT Family, Genus, Species, COUNT(Subspecies)
  AS NumberOfSubspecies
  FROM chir
  Where Species <> ""
  GROUP BY Genus, Species
               ')   



# I think each species has 1 row for species and extra rows for subspecies
#   Check this is true. 
#   If that is correct, then Species with >1 NumberOfSubspecies should be one less.

SpeciesRows <- sqldf('
  SELECT Genus, Species, COUNT(Subspecies)
  AS SpeciesRows
  FROM chir
  WHERE Subspecies == "" AND Species <> ""
  GROUP BY Genus, Species
               ') 

# 
(SpeciesRows$SpeciesRows != 1) %>% sum
all(SpeciesRows$SpeciesRows == 1)

# Species with >1 NumberOfSubspecies should be one less
subs$NumberOfSubspecies <- ifelse(subs$NumberOfSubspecies > 1, 
                             subs$NumberOfSubspecies - 1, 
                             subs$NumberOfSubspecies)

# Quick look at species with highest number of subspecies.
subs[order(subs$NumberOfSubspecies, decreasing = TRUE ),] %>% head

# Megaderma spasma is top. It's widespread across south east asia islands. 
#   So this makes sense.

# Quick look at the number of subspecies.
ggplot(subs, aes(x = NumberOfSubspecies)) +
  geom_histogram() +
  xlab('Number of Subspecies') +
  ylab('Count')


# Create a combined binomial name column
subs$binomial <- paste(subs$Genus, subs$Species)




# Check overlap of datasets.
sum(!(virus2$binomial[virus2$host.species != ''] %in% subs$binomial))

notInTax <- (virus2$binomial[virus2$host.species != ''])[!(virus2$binomial[virus2$host.species != ''] %in% subs$binomial)]

# Run this to find synonyms of names not in Wilson and Reeder
#   Doesn't find much of use.
# syns <- synonyms(notInTax, db = 'itis')

# Clean some names
#  As taxize::synonyms didn't find most of them, I am using IUCN.
#  And checking that the IUCN name is then in The Wilson & Reeder taxonomy

virus2$binomial[virus2$binomial == 'Myotis pilosus'] <- 'Myotis ricketti'
virus2$binomial[virus2$binomial == 'Tadarida pumila'] <- 'Chaerephon pumilus'
virus2$binomial[virus2$binomial == 'Tadarida condylura'] <- 'Mops condylurus'
virus2$binomial[virus2$binomial == 'Rhinolophus hildebrandti'] <- 'Rhinolophus hildebrandtii'
# Rhinolophus horsfeldi: I can't find this species anywhere. Will exclude.
#   Possibly Megaderma spasma according to http://www.fao.org/3/a-i2407e.pdf
virus2$binomial[virus2$binomial == 'Tadarida plicata'] <- 'Chaerephon plicatus'
virus2$binomial[virus2$binomial == 'Artibeus planirostris'] <- 'Artibeus jamaicensis'

sum(!(virus2$binomial[virus2$host.species != ''] %in% subs$binomial))

%%end.rcode

%%begin.rcode subsHistsByFam, fig.show = extraFigs, fig.height = 3, fig.cap = 'Histograms of number of subspecies for the families with many species.'

# Compare the histograms of numbers of subspecies over the families with many species.
subs %>%
  filter(Family %in% names(which(table(subs$Family) > 99))) %>%
  ggplot(., aes(x = NumberOfSubspecies, y = ..density..)) + 
    geom_histogram() +
    facet_grid(. ~ Family) +
    xlab('Number of Subspecies') +
    ylab('Density')

%%end.rcode

%%begin.rcode, subvsvirusCaption

# Caption for subspecies vs n. viruses plot.
subvsvirus <- '
Number of viruses against number of subspecies.
Points are coloured by family, with families with less than 10 species being grouped into "other".
Contours show the 2D density of points and suggest a positive correlation.
'
subvsvirusTitle <- 'Number of viruses against number of subspecies.'
%%end.rcode

%%begin.rcode subsDataFrame, fig.show = extraFigs, fig.cap = subvsvirus, fig.scap = subvsvirusTitle, out.width = '\\textwidth'
# create combined dataframe

# Join dataframes
species <- sqldf("
               SELECT subs.binomial, virus2.[virus.species]
               FROM subs
               INNER JOIN virus2
               ON subs.binomial=virus2.binomial;
              ")
                        
# Count number of virus species for each bat species
nSpecies <- species %>%
              unique %>%
              group_by(binomial) %>%
              summarise(virusSpecies = n())
        
# Add other Subspecies data.
nSpecies <- sqldf("
              SELECT nSpecies.binomial, virusSpecies, NumberOfSubspecies, Genus, Family
              FROM nSpecies
              LEFT JOIN subs
              ON nSpecies.binomial=subs.binomial
             ")

# Create another column to make plotting easier.
#   Group families with few rows into 'other'

nSpecies$familyPlotCol <- nSpecies$Family
nSpecies$familyPlotCol[
  nSpecies$Family %in% names(which(table(nSpecies$Family) < 10))] <- 'Other'

table(nSpecies$familyPlotCol)

ggplot(nSpecies, aes(x = log(NumberOfSubspecies), y = log(virusSpecies))) +
  # geom_smooth(method = 'lm') +
  geom_jitter(aes(colour = familyPlotCol), size = 2.5, alpha = 0.8, 
    position = position_jitter(width = .1, height = .1)) +
  scale_colour_hc() +
  geom_density2d() +
  labs(colour = 'Family')
  
%%end.rcode

%%begin.rcode virusHist, fig.show = extraFigs, fig.cap = 'Histogram of known viruses per species'

ggplot(nSpecies, aes(x = virusSpecies)) +
  geom_histogram()

%%end.rcode




%%begin.rcode euthRead

# Read in pantheria data base
pantheria <- read.table(file = 'data/Chapter3/PanTHERIA_1-0_WR05_Aug2008.txt',
  header = TRUE, sep = "\t", na.strings = c("-999", "-999.00"))

mass <- sqldf("
  SELECT [X5.1_AdultBodyMass_g]
  FROM nSpecies
  LEFT JOIN pantheria
  ON nSpecies.binomial=pantheria.MSW05_Binomial
  ")

nSpecies$mass <- mass[, 1]

# Now add additional mass estimates.

additionalMass <- read.csv('data/Chapter3/AdditionalBodyMass.csv', stringsAsFactors = FALSE)
meanAdditionalMass <- additionalMass %>%
                        group_by(binomial) %>% 
                        summarise(mass = mean(Body.Mass.grams))

nSpecies$mass[
  sapply(meanAdditionalMass$binomial, function(x) which(nSpecies$binomial == x))
  ] <- meanAdditionalMass$mass 


%%end.rcode



%%begin.rcode IUCNranges

# Read in iucn ranges and calculate range sizes for each species.
ranges <- readShapePoly('data/Chapter3/TERRESTRIAL_MAMMALS/TERRESTRIAL_MAMMALS.shp')

levels(ranges$binomial) <- c(levels(ranges$binomial), 'Myotis ricketti')
ranges$binomial[ranges$binomial == 'Myotis pilosus'] <- 'Myotis ricketti'


#rm(ranges)

nSpecies$binomial[!(nSpecies$binomial %in% ranges$binomial)]

findArea <- function(name){
  #cat(name)
  A <- areaPolygon(ranges[ranges$binomial == name, ])
  sum(A)
}

iucnDistr <- sapply(nSpecies$binomial, findArea)


nSpecies$distrSize <- iucnDistr

%%end.rcode


%%begin.rcode pubmedScrapeFunc

# Scrape from pubmed

scrapePub <- function(sp){
    
  Sys.sleep(2)

  # Initialise refs
  refs <- NA

  # Find synonyms from taxize
  syns <- synonyms(sp, db = 'itis')
  if(NROW(syns[[1]]) == 1){
    spString <- tolower(gsub(' ', '%20', sp))
  } else {
    spString <- paste(tolower(gsub(' ', '%20', syns[[1]]$syn_name)), collapse = '%22+OR+%22')
  }


  url <- paste0('http://www.ncbi.nlm.nih.gov/pubmed/?term=%22', spString, '%22')


  page <- html(url)
  
  # Test if exact phrase was found.
  phraseFound <- try(page %>% 
                   html_node('.icon') %>%
                   html_text() %>%
                   grepl("The following term was not found in PubMed:", .), silent = TRUE)

  if (class(phraseFound) == "logical") {
    if(phraseFound){
      if(phraseFound) refs <- NA
    }
  } 
  if (class(phraseFound) != "logical") {
    try({
    refs <- page %>%
              html_node('.result_count') %>%
              html_text() %>%
              strsplit(' ') %>% 
              .[[1]] %>%
              .[length(.)] %>%
              as.numeric()
    })
  }

  return(refs)
}


%%end.rcode


%%begin.rcode pubmedScrape, eval = runPubmedScrape

# Create empty vector
pubmedRefs <- rep(NA, nrow(nSpecies))

for(i in 1:NROW(nSpecies)){
  pubmedRefs[i] <- scrapePub(nSpecies$binomial[i])
}

pubmedScrapeDate <- Sys.Date()

pubmedRefs <- cbind(binomial = nSpecies$binomial, pubmedRefs = pubmedRefs)

# Write out.
write.csv(pubmedRefs, file = 'data/Chapter3/pubmedRefs.csv')

%%end.rcode




%%begin.rcode pubmedRead


pubmedRefs <- read.csv('data/Chapter3/pubmedRefs.csv', stringsAsFactors = FALSE, row.names = 1)

# Function returns NA for none found. Change that to a zero.
pubmedRefs$pubmedRefs[is.na(pubmedRefs$pubmedRefs)] <- 0
nSpecies$pubmedRefs <- pubmedRefs$pubmedRefs

%%end.rcode

%%begin.rcode scholarScrapeFunc

scrapeScholar <- function(sp){
    
  wait <- rnorm(1, 120, 2)
  Sys.sleep(wait)


  syns <- synonyms(sp, db = 'itis')
  if(NROW(syns[[1]]) == 1){
    spString <- tolower(gsub(' ', '%20', sp))
  } else {
    spString <- paste(tolower(gsub(' ', '%20', syns[[1]]$syn_name)), collapse = '%22+OR+%22')
  }

  url <- paste0('https://scholar.google.co.uk/scholar?hl=en&q=%22', 
                spString, '%22&btnG=&as_sdt=1%2C5&as_sdtp=')


  page <- html(url)
  
  try({
  refs <- page %>%
            html_node('#gs_ab_md') %>%
            html_text() %>%
            gsub('About\\s(.*)\\sresults.*', '\\1', .) %>%
            gsub(',', '', .) %>%
            as.numeric
  })
  return(refs)
}

%%end.rcode

%%begin.rcode scholarScrape, eval = runScholarScrape

# Create empty vector
scholarRefs <- rep(NA, nrow(nSpecies))

for(i in 1:NROW(nSpecies)){
  scholarRefs[i] <- scrapeScholar(nSpecies$binomial[i])
}

scholarScrapeDate <- Sys.Date()

scholarRefs <- cbind(binomial = nSpecies$binomial, scholarRefs = scholarRefs)

# Write out.
write.csv(scholarRefs, file = 'data/Chapter3/scholarRefs.csv')

%%end.rcode




%%begin.rcode scholarRead


scholarRefs <- read.csv('data/Chapter3/scholarRefs.csv', stringsAsFactors = FALSE, row.names = 1)

# Function returns NA for none found. Change that to a zero.
scholarRefs$scholarRefs[is.na(scholarRefs$scholarRefs)] <- 0

nSpecies$scholarRefs <- sqldf('
  SELECT scholarRefs
  FROM nSpecies
  INNER JOIN scholarRefs
  ON scholarRefs.binomial=nSpecies.binomial
  '
  ) %>%
  .$scholarRefs

%%end.rcode







%%begin.rcode subsRemoveNAs

# Remove missing data and sort out the data frame a little.

nSpecies <- nSpecies[complete.cases(nSpecies), ]

# Add number of subspecies as a factor. Might help plotting.
nSpecies$SubspeciesFactor <- factor(nSpecies$NumberOfSubspecies, 
  levels = as.character(1:max(nSpecies$NumberOfSubspecies)))

# Rownames to species names
rownames(nSpecies) <- nSpecies$binomial

%%end.rcode



%%begin.rcode savenSpecies
########################################################
### At this point, nSpecies should be in final form  ###
########################################################

write.csv(nSpecies, file = 'data/Chapter3/nSpecies.csv')

%%end.rcode

To measure pathogen richness I used data from \cite{luis2013comparison}. 
These simply include known infections of a bat species with a pathogen species. 
Only species with at least one pathogen were included in the analysis.
Rows with host species that were not identified to species level were removed.
Many viruses were not identified to species level or their identified species was not in the ICTV virus taxonomy \cite{ICTV}.
I counted a virus if it was the only virus, for that host species, in the lowest taxonomic level identified in the ICTV taxonomy.
That is, if a host carries an unknown Paramyxoviridae virus, then it must carry at least one Paramyxoviridae virus.
If a host carries an unknown Paramyxoviridae virus and a known Paramyxoviridae virus, then it is hard to confirm that the unknown virus is not another record of the known virus.
In this case, this would be counted as one virus species.



%%begin.rcode treeRead

# Read in trees
t <- read.nexus('data/Chapter3/fritz2009geographical.tre')

# Select best supported tree
tr1 <- t[[1]]

# Make names match previous names
tr1$tip.label <- gsub('_', ' ', tr1$tip.label)

# Which tips are not needed
unneededTips <- tr1$tip.label[!(tr1$tip.label %in% nSpecies$binomial)]

# Prune tree down to only needed tips.
pruneTree <- drop.tip(tr1, unneededTips)

rm(t)

%%end.rcode


%%begin.rcode treePlot, out.width = '\\textwidth', fig.cap = 'Pruned phylogeny with dot size showing number of pathogens and colour showing family.'

# Plot tree 
p <- ggtree(pruneTree, layout = 'fan') 

p %<+% nSpecies[, 1:6] +
  geom_point(aes(size = virusSpecies, colour = Family), subset=.(isTip)) +
  scale_size(range = c(0.8, 3)) +
  scale_colour_manual(values = c(pokepal('oddish')[c(1,3,5,6,9,10)],    pokepal('Carvanha')[c(1,2,4, 13, 12)])) +
  theme_tcdl +
  theme(plot.margin = unit(c(-1, 3, -2.5, -2), "lines")) +
  theme(legend.position = 'right') +
  labs(size = 'Virus Richness') +
  theme(legend.key.size = unit(0.6, "lines"),
              legend.text = element_text(size = 6),
              legend.title = element_text(size = 8))


%%end.rcode



%%begin.rcode scholarvspubmed, fig.show = extraFigs, fig.cap = 'Logged number of references on scholar and pubmed, with a fitted (unphylogenetic) linear model. Colours indicate family.'

# Check how correlated pubmed and scholar are.


compSubspecies <- comparative.data(data = nSpecies, phy = pruneTree, names.col = 'binomial')

citeCor <- pgls(log(scholarRefs) ~ log(pubmedRefs + 1), data = compSubspecies, lambda = 'ML')

studyEffortCor <- summary(citeCor)
# And plot
ggplot(nSpecies, aes(x = scholarRefs, y = pubmedRefs + 1)) +
  geom_point(aes(colour = familyPlotCol), size = 2.5) +
  geom_smooth(method = 'lm') +
  scale_x_log10() +
  scale_y_log10() +
  scale_colour_hc()

%%end.rcode

%%begin.rcode subsDataCapts
subsDataCapts <- c(
'Unlogged number of virus species against log mass with a non-phylogenetic linear model added. Points are significantly jittered to try and reveal the severe overplotting in the bottom left corner in particular.',
'Number of virus species against logged number of subspecies (not marginal) with a non-phylogenetic linear model added. Points are significantly jittered to try and reveal the severe overplotting in the bottom left corner in particular.', 
'Number of virus species against logged number of subspecies (not marginal) with a non-phylogenetic linear model added.', 
'Virus species against study effort (log pubmed references +1)')
%%end.rcode

%%begin.rcode subsDataviz, fig.show = extraFigs, fig.cap = subsDataCapts

# A number of exploratory plots

# Mass against viruses
ggplot(nSpecies, aes(log(mass), virusSpecies)) +
  geom_point(aes(colour = familyPlotCol), size = 2.5) + 
  geom_smooth(method = 'lm')+
  labs(colour = 'Family') +
  scale_colour_hc()



# N Subspecies and against viruses
ggplot(nSpecies, aes(NumberOfSubspecies, virusSpecies)) +
  geom_jitter(aes(colour = familyPlotCol), size = 2.5, 
    position = position_jitter(width = .3, height = .3)) + 
  geom_smooth(method = 'lm')+
  labs(colour = 'Family') +
  scale_colour_hc()


# Log(N Subspecies) and against viruses

ggplot(nSpecies, aes(NumberOfSubspecies, virusSpecies)) +
  geom_jitter(aes(colour = familyPlotCol), size = 2.5, 
    position = position_jitter(width = .05, height = .2)) +
  scale_x_log10() + 
  geom_smooth(method = 'lm')+
  labs(colour = 'Family') +
  scale_colour_hc()


# N. Subspecies against viruses as a boxplot to deal with overplotting.
ggplot(nSpecies, aes(SubspeciesFactor, virusSpecies)) +
  geom_boxplot() +
  scale_x_discrete(limits = levels(nSpecies$SubspeciesFactor), drop=FALSE) +
  geom_smooth(method = 'lm', aes(group = 1)) +
  xlab('# subspecies')


# Study effort against virusSpecies
ggplot(nSpecies, aes(log(pubmedRefs + 1), virusSpecies)) +
  geom_jitter(aes(colour = familyPlotCol), size = 2.5, 
    position = position_jitter(width = .1, height = .1)) + 
  geom_smooth(method = 'lm') +
  labs(colour = 'Family')+
  scale_colour_hc()


# Distribution size aginst virus


ggplot(nSpecies, aes(distrSize, virusSpecies)) +
  geom_point(aes(colour = familyPlotCol), size = 2.5) + 
  geom_smooth(method = 'lm') +
  labs(colour = 'Family') +
  scale_colour_hc() +
  scale_x_log10()


# Correlation plot
nSpecies %>%
  dplyr::select(virusSpecies, NumberOfSubspecies, mass, distrSize, pubmedRefs, scholarRefs) %>%
  mutate(mass = log(mass), distrSize = log(distrSize), pubmedRefs = log(pubmedRefs + 1), scholarRefs = log(scholarRefs)) %>%
  ggpairs(.)

%%end.rcode




I used two measures of population structure. 
$F_{ST}$ and the number of subspecies.
The number of subspecies was counted using the Wilson and Reeder taxonomy \cite{wilson2005mammal}.
$F_{ST}$ and other measures were collated from the literature.
Studies are from a wide range of spatial scales, from local ($\sim\SI{10}{\kilo\metre}$) to continental.
As $F_{ST}$ inevitably increases with spatial scale I controlled for this by only using data from studies where a large proportion of the species range was studied.
I used the ratio of the furthest distance between $F_{ST}$ samples (measured with \url{http://www.distancefromto.net/} if not stated) to the width of the IUCN species range and only used studies if this ratio was greater than \rinline{rangeUseable}.
To allow comparison between different measures ($F_{ST}, \phi_{ST}$) and data from different molecular regions I converted all data to diploid gene flow.
WILL ADD EXTRA METHODS LATER.
These two measures of population structure were analysed separately as the number of subspecies has \rinline{nrow(nSpecies)} data points while there is only $F_{ST}$ data for $\sim 30$ bat species.

To control for study bias I collected the number of Pubmed and Google Scholar citations for each bat species including synonyms from ITIS \cite{itis} via the taxize package \cite{chamberlain2013taxize}.
The counts were scraped using the rvest package \cite{rvest}.
I log transformed these variables as they were strongly right skewed.
The log number of citations on Pubmed and Google scholar were highly correlated (pgls: $t$ = \rinline{studyEffortCor$coefficients['log(pubmedRefs + 1)', 't value']}, df = \rinline{studyEffortCor$df[2]}, $p$ = \rinline{studyEffortCor$coefficients['log(pubmedRefs + 1)', 'Pr(>|t|)']}).
The results here are for analyses using only Google Scholar citations.
See the appendix for analyses run using Pubmed citations.

Measures of body mass are taken from Pantheria \cite{jones2009pantheria} and primary literature \cite{canals2005relative, arita1993rarity, lopez2014echolocation, orr2013does, , lim2001bat, aldridge1987turning, ma2003dietary, owen2003home, henderson2008movements, heaney2012nyctalus, oleksy2015high, zhang2009recent}. 
\emph{Pipistrellus pygmaeus} was assigned the same mass as \emph{P. pipistrellus} as they indistinguishable by mass.
Body mass measurements were log transformed due to the strong right skew.
Distribution size was estimated by downloading range maps for all species from IUCN \cite{} and were also logged due to right skew.

%Pubmed was scraped on \rinline{pubmedScrapeDate} and Google Scholar was scraped on \rinline{scholarScrapeDate}

To control for phylogenetic nonindependance I used the best-supported phylogeny from \cite{fritz2009geographical} which is the supertree from \cite{bininda2007delayed} with names updated to match the Wilson \& Reeder taxonomy \cite{wilson2005mammal}.
Phylogenetic manipulation was performed using the ape package \cite{ape}.
The importance of the phylogeny on each variable separately was estimated using \cite{phytools}.





%%begin.rcode diagCapts
diagCapts <- c(
'Fitted values against residuals from the full phylogenetic model (virusSpecies $\\sim$ log(scholarRefs) + log(NumberOfSubspecies) +  log(mass)). A loess curve is shown in blue. 
The $R^2$ value give is for the full model (not the loess curve).',
'Study effort against residuals with a loess trend.',
'Mass against residuals with a loess trend shown in blue.',
'Logged number of subspecies against phylogenetic residuals. The mean for each value of logged subspecies is shown in blue. A ribbon showing the mean $\\pm 1.96{SD}$ is shown in grey. The ribbon does not cover the full range of the x axis as there are not enough data points to calculate the SD towards the right.',
'Fitted values against residuals from the full phylogenetic model (virusSpecies $\\sim$ NumberOfSubspecies + log(pubmedRefs + 1) +   log(mass)). A loess curve is shown in blue.
The $R^2$ value give is for the full model (not the loess curve).',
'Study effort against residuals (unlogged subspecies) with a loess trend.',
'Mass against residuals  (unlogged subspecies) with a loess trend shown in blue.',
'Number of subspecies against phylogenetic residuals. The mean for each value of logged subspecies is shown in blue. A ribbon showing the mean $\\pm 1.96{SD}$ is shown in grey. The ribbon does not cover the full range of the x axis as there are not enough data points to calculate the SD towards the right.'
)


%%end.rcode

%%begin.rcode, subsAnalysis, fig.show = extraFigs, fig.cap = diagCapts, fig.height = 4

# Fit phylogenetic models and look at diagnostic plots.

# N Virus ~ log(subs + cites + mass)

subspeciesJoint <- pgls(
  virusSpecies ~ log(scholarRefs) + log(NumberOfSubspecies) +  log(mass) , 
  data = compSubspecies, lambda = 'ML')

subJoint.summary <- summary(subspeciesJoint)

# Create dataframe for diagnostic residuals plot.
jointDiag <- data.frame(
   PhylogeneticResiduals = subspeciesJoint$phyres,
   FittedValue = subspeciesJoint$fitted,
   Subspecies = subspeciesJoint$x[, 'log(NumberOfSubspecies)'],
   Mass = subspeciesJoint$x[, 'log(mass)'],
   StudyEffort = subspeciesJoint$x[, 'log(scholarRefs)'])

# Plot residuals.
          
ggplot(jointDiag, aes(x = FittedValue, y = PhylogeneticResiduals)) +
  geom_point() +
  geom_smooth(method = 'loess') +
   geom_text(aes(x = 6, y = -1, 
    label =  paste("R^2 == ", round(subJoint.summary$r.squared, 2),sep="")), 
    parse = TRUE) 


ggplot(jointDiag, aes(x = StudyEffort, y = PhylogeneticResiduals)) +
  geom_point() +
  geom_smooth(method = 'loess')

ggplot(jointDiag, aes(x = Mass, y = PhylogeneticResiduals)) +
  geom_point() +
  geom_smooth(method = 'loess')

# Create data to check heteroscadasticity
jointSD <- data.frame(
  Subspecies = unique(jointDiag$Subspecies),
  SD = sapply(unique(jointDiag$Subspecies), function(x)
        jointDiag %>%
          filter(Subspecies == x) %>%
          dplyr::select(PhylogeneticResiduals) %>%
          .[,1] %>%
          sd
      ),
  Mean = sapply(unique(jointDiag$Subspecies), function(x)
        jointDiag %>%
          filter(Subspecies == x) %>%
          dplyr::select(PhylogeneticResiduals) %>%
          .[,1] %>%
          mean
      )
)
# Look at heteroscedasticity.

ggplot(jointSD, aes(x = Subspecies)) +
  geom_ribbon(aes(ymax = Mean + 1.96*SD, ymin = Mean - 1.96*SD),
    alpha = 0.4) +
  geom_line(aes(y = Mean), colour = 'SteelBlue') +
  geom_point(data = jointDiag, 
    aes(x = Subspecies, y = PhylogeneticResiduals))



#################################################################################
# N Virus ~ subs + log(cites + mass)

subspeciesJointUnlog <- pgls(
  virusSpecies ~ log(scholarRefs) + NumberOfSubspecies +  log(mass), 
  data = compSubspecies, lambda = 'ML')


subspeciesJointUnlog.summary <- summary(subspeciesJointUnlog)

#par(mfrow = c(2, 2))
plot(subspeciesJointUnlog)

lambda.profile <- pgls.profile(subspeciesJointUnlog, "lambda")
#plot(lambda.profile)


jointDiagUnlog <- data.frame(
   PhylogeneticResiduals = subspeciesJointUnlog$phyres,
   FittedValue = subspeciesJointUnlog$fitted,
   Subspecies = subspeciesJointUnlog$x[, 'NumberOfSubspecies'],
   Mass = subspeciesJointUnlog$x[, 'log(mass)'],
   StudyEffort = subspeciesJointUnlog$x[, 'log(scholarRefs)'])


           
ggplot(jointDiagUnlog, aes(x = FittedValue, y = PhylogeneticResiduals)) +
  geom_point() +
  geom_smooth(method = 'loess') +
  geom_text(aes(x = 6, y = -1, 
    label =  paste("R^2 == ", round(subspeciesJointUnlog.summary$r.squared, 2),sep="")), 
    parse = TRUE) 


ggplot(jointDiagUnlog, aes(x = StudyEffort, y = PhylogeneticResiduals)) +
  geom_point() +
  geom_smooth(method = 'loess')

ggplot(jointDiagUnlog, aes(x = Mass, y = PhylogeneticResiduals)) +
  geom_point() +
  geom_smooth(method = 'loess')

jointSDUnlog <- data.frame(
  Subspecies = unique(jointDiagUnlog$Subspecies),
  SD = sapply(unique(jointDiagUnlog$Subspecies), function(x)
        jointDiagUnlog %>%
          filter(Subspecies == x) %>%
          dplyr::select(PhylogeneticResiduals) %>%
          .[,1] %>%
          sd
      ),
  Mean = sapply(unique(jointDiagUnlog$Subspecies), function(x)
        jointDiagUnlog %>%
          filter(Subspecies == x) %>%
          dplyr::select(PhylogeneticResiduals) %>%
          .[,1] %>%
          mean
      )
)

ggplot(jointSDUnlog, aes(x = Subspecies)) +
  geom_ribbon(aes(ymax = Mean + 1.96*SD, ymin = Mean - 1.96*SD),
    alpha = 0.4) +
  geom_line(aes(y = Mean), colour = 'SteelBlue') +
  geom_point(data = jointDiagUnlog, 
    aes(x = Subspecies, y = PhylogeneticResiduals))




# N Virus ~ subs + log(cites + mass) + subs*log(cites)

subspeciesInter <- pgls(
  virusSpecies ~ log(mass) + 
  NumberOfSubspecies*log(scholarRefs), 
  data = compSubspecies, lambda = 'ML')

subInter.summary <- summary(subspeciesInter)


# Model using residuals from first model going into second model
# I don't use this model in the analysis in the end.
# It gives precedence to study effort when it's better to fit at the same time.
# glm(N Virus ~ cites)$resid ~ subs + subs*cites

subspeciesEffort <- pgls(virusSpecies ~ log(scholarRefs), 
  data = compSubspecies, lambda = 'ML')

nSpecies$pubmedResid <- subspeciesEffort$phyres[order(rownames(subspeciesEffort$residuals))]

compSubspeciesResid <- comparative.data(data = nSpecies, phy = pruneTree, names.col = 'binomial')

subspeciesResid <- pgls(pubmedResid ~ log(NumberOfSubspecies) + log(mass), 
  data = compSubspeciesResid, lambda = 'ML')

summary(subspeciesResid)
#plot(subspeciesResid)


# Compare AICs

nSubSpAIC <- AIC(subspeciesJoint, subspeciesJointUnlog, subspeciesInter)



# Look at Variance inflation factors.
#   Couple of help messages imply lm vif is fine.

sqrt(vif(lm(virusSpecies ~ log(scholarRefs) + NumberOfSubspecies +  log(mass) + log(distrSize), data = nSpecies)))

%%end.rcode
%\clearpage




%begin.rcode boxplotCapt

# Caption for the main boxploit of subspecies vs virus

boxplotCapt <- c('Number of virus species against number of subspecies. 
Data within a number of subspecies are plotted as boxplots with the dark bar showing the median, the box showing the interquartile range, vertical lines showing the range and outliers shown as seperate points.
Regression lines are from multivariate phylogenetic models with other independant variables set at their median value.
The models shown are thos with (pink) and without (red) an interaction between study effort and number of subspecies.
',
'Histogram of number of subspecies. 
It is clear that more species have fewer subspecies.')

boxplotTitle = c('Number of virus species against number of subspecies', 'Histogram of number of subspecies')

%%end.rcode


%%begin.rcode boxplot, fig.cap = boxplotCapt, fig.scap = boxplotTitle


# Make a boxplot of subspecies vs virus
# Add model lines for pgls models.

# Make predictions of model w/out interactions using median values of other variables.

predData <- data.frame(scholarRefs = quantile(nSpecies$scholarRefs, 0.5),
                       mass = quantile(nSpecies$mass, 0.5),
                       NumberOfSubspecies =
                         seq(min(nSpecies$NumberOfSubspecies), max(nSpecies$NumberOfSubspecies), 
                         length.out = 200)
                       )


lines <- data.frame(NumberOfSubspecies = predData$NumberOfSubspecies, 
               virusSpecies = predict(subspeciesJointUnlog, newdata = predData))

# Make predictions of model w/ interactions using median values of other variables.

predDataInter <- data.frame(scholarRefs = quantile(nSpecies$scholarRefs, 0.5),
                       mass = quantile(nSpecies$mass, 0.5),
                       NumberOfSubspecies =
                         seq(min(nSpecies$NumberOfSubspecies), max(nSpecies$NumberOfSubspecies), 
                         length.out = 200)
                       )


linesInter <- data.frame(NumberOfSubspecies = predData$NumberOfSubspecies, 
               virusSpecies = predict(subspeciesInter, newdata = predDataInter))


# Make plot

ggplot(nSpecies, aes(SubspeciesFactor, virusSpecies, colour = 'a', fill = 'a')) + 
  geom_boxplot(outlier.size = 1, size = 0.3, outlier.colour = grey(0.3), 
    notch = FALSE) +
  scale_colour_manual(values = pokepal('nidorina')[4]) +
  scale_fill_manual(values = pokepal('nidorina')[2]) +
  stat_summary(geom = "crossbar", width = 0.7, fatten = 2, 
    fun.data = function(x){ return(c(y = median(x), ymin = median(x), ymax = median(x))) }) +
  theme(legend.position = 'none') + 
  scale_x_discrete(limits = levels(nSpecies$SubspeciesFactor), drop = FALSE) +
  xlab('N. of Subspecies') +
  ylab('Viral Richness') +
  geom_line(data = lines, aes(x = NumberOfSubspecies, y = virusSpecies, group = 1),
    colour = pokepal('nidorina')[10], lwd = 1) +
  geom_line(data = linesInter, aes(x = NumberOfSubspecies, y = virusSpecies, group = 1),
    colour = pokepal('nidorina')[13], lwd = 1) +
    annotate('text', x = c(11.8, 12.2), y = c(5.2, 2.7), 
      label = c('No interaction', 'Interaction'),
      colour = pokepal('nidorina')[c(10,13)], size = c(3, 3),
      family = 'Lato Light')

# Histogram of subspecies.
ggplot(nSpecies, aes(x = SubspeciesFactor)) + 
  geom_histogram() +
  xlab('N. of Subspecies') +
  ylab('Count') +
  scale_x_discrete(limits = levels(nSpecies$SubspeciesFactor), drop = FALSE)

%%end.rcode

%%begin.rcode ITanalysis

varList <- c('log(scholarRefs)', 'NumberOfSubspecies', 'log(mass)', 'log(distrSize)', 'rand')

findCombs <- function(k, vars, longest){
  x <- t(combn(vars, k))
  nas <- matrix(NA, ncol = longest - NCOL(x), nrow = nrow(x))
  mat <- cbind(x, nas)
  return(mat)
}

modelList <- lapply(0:5, function(k) findCombs(k, varList, 6))
modelMat <- do.call(rbind, modelList)

interMat <- modelMat[apply(modelMat, 1, function(x) "log(scholarRefs)" %in% x & "NumberOfSubspecies" %in% x), ]
interMat[, 2:5] <- interMat[, 1:4]
interMat[, 1] <- "log(scholarRefs):NumberOfSubspecies"

allModelMat <- rbind(modelMat, interMat)


allFormulae <- apply(allModelMat[-1, ], 1, function(x) as.formula(paste('virusSpecies ~', paste(x[!is.na(x)], collapse = ' + '))))

allFormulae <- c(as.formula('virusSpecies ~ 1'), allFormulae)



modelSelect <- function(allForm, data, phy, boot, allModelMat, varList){
  
  set.seed(paste0('123', boot))
  bootData <- cbind(data, rand = runif(nrow(data)))
  #compBootData <- comparative.data(data = bootData, phy = phy, names.col = 'binomial')

  results <- apply(allModelMat, 1, function(x) sapply(c(varList, "log(scholarRefs):NumberOfSubspecies"), function(y) y %in% x)) %>%
               t %>%
               data.frame %>%
               cbind(AIC = NA, boot = boot, lambda = NA)

  for(m in 1:length(allForm)){
    model <- gls(allForm[[m]], correlation = corPagel(value = 0.5, phy = phy), data = bootData, method = 'ML')    
    #model <- pgls(allForm[[m]], data = compBootData, lambda = 'ML')
    results$AIC[m] <- AICc(model)
    results$lambda[m] <- model$modelStruct$corStruct[1]
    results$predictors[m] <- allForm[[m]] %>% as.character %>% .[3]
    message(paste('Boot:', boot, ', m:', m, '\n'))
  }

  results$dAIC <- results$AIC - min(results$AIC)
  results$weight <- exp(- 0.5 * results$dAIC) / sum(exp(- 0.5 * results$dAIC))


  return(results)

}




%%end.rcode

%%begin.rcode modelSelectBoots, eval = subBoots

fitModelsBootStrap <- mclapply(1:nBoots, function(b) modelSelect(allFormulae, nSpecies, pruneTree, b, allModelMat, varList), mc.cores = nCores)

allResults <- do.call(rbind, fitModelsBootStrap)

write.csv(allResults, file = 'data/Chapter3/modelSelectSubspecies.csv')


%%end.rcode

%%begin.rcode analyseModelSelect, fig.show = extraFigs

allResults <- read.csv('data/Chapter3/modelSelectSubspecies.csv', row.names = 1)

varWeights <- sapply(names(allResults)[1:6], function(x) sum(allResults$weight[allResults[, x]])/nBoots)


sepVarWeights <- lapply(1:nBoots, function(b) 
                      sapply(names(allResults)[1:6], 
                        function(x) 
                          sum(allResults[allResults$boot == b, 'weight'][allResults[allResults$boot == b, x]])
                      )
                     )      

sepVarWeights <- do.call(rbind, sepVarWeights) %>%
                      data.frame(., boot = 1:nBoots) %>%
                      reshape2::melt(., value.name = 'estimate', id.vars = 'boot')

sepVarWeights$col <- 'Other Variables'
sepVarWeights$col[grep('NumberOf', sepVarWeights$variable)] <- 'Population Structure'
sepVarWeights$col[sepVarWeights$variable == 'rand'] <- 'Null'



modelWeights <- allResults %>%
                  group_by(predictors) %>%
                  summarise(AICc = mean(AIC)) %>%
                  mutate(dAIC = AICc - min(AICc), modelWeight = exp(- 0.5 * dAIC) / sum(exp(- 0.5 * dAIC))) %>%
                  arrange(desc(modelWeight)) %>%
                  mutate(cumulativeWeight = cumsum(modelWeight)) %>%
                  mutate(string = levels(predictors)[predictors])


allResults %>% 
  filter(rand, !log.scholarRefs..NumberOfSubspecies, NumberOfSubspecies) %>%
ggplot(., aes(x = lambda, colour = predictors)) + 
  geom_density() +
  scale_colour_hc()

ggplot(allResults, aes(x = lambda)) + 
  geom_density() 

allResults %>% 
  filter(boot == 1) %>%
  dplyr::select(predictors, lambda)

%%end.rcode



%%begin.rcode ITPlots, fig.cap = "Akaika variable weights for number of subspecies analysis. The probability that each variable will be in the best model if the data were recollected is shown for each of the bootstrap analyses. The purple ``Null'' box is a uniform random variable used as a null. Population structure (Number of subspecies) and the interaction between subspecies and study effort, shown in red, are more likely to be in the best model than this random variable.", fig.height = 3.8, fig.scap = "Akaika variable weights for number of subspecies analysis"

ggplot(sepVarWeights, aes(x = variable, y = estimate, colour = col, fill = col)) +
  geom_boxplot(outlier.colour = grey(0.3), notch = FALSE, notchwidth = 0.7) +
  scale_colour_manual(values = pokepal('nidorino')[c(2, 5, 11)]) +
  scale_fill_manual(values = pokepal('nidorino')[c(3, 6, 10)]) +
  theme(legend.position = 'none', axis.text.x = element_text(size = 15, angle = 45, hjust = 1)) +
  scale_x_discrete(labels = c('Study Effort', 'Subspecies', 'Mass', 'Range Size', 'Null', 'Subspecies:Effort'))+
  ylab('P(in best model)') +
  xlab('')



%%end.rcode


%%begin.rcode familyMeans

familyMeans <- nSpecies %>%
  group_by(Family) %>%
  summarise(mean = mean(virusSpecies), n = n()) 

%%end.rcode


%%begin.rcode univariatePGLS

orderedNSpecies <- nSpecies[sapply(pruneTree$tip.label, function(x) which(nSpecies$binomial == x)),]


sspLambda <- summary(pgls(NumberOfSubspecies ~ 1, data = compSubspecies, lambda = 'ML'))
massLambda <- summary(pgls(log(mass) ~ 1, data = compSubspecies, lambda = 'ML'))
scholarLambda <- summary(pgls(log(scholarRefs) ~ 1, data = compSubspecies, lambda = 'ML'))
virusLambda <- summary(pgls(virusSpecies ~ 1, data = compSubspecies, lambda = 'ML'))
distrLambda <- summary(pgls(distrSize ~ 1, data = compSubspecies, lambda = 'ML'))
%%end.rcode
\clearpage





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% FST ANALYSIS                                                                                                                                  %%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%begin.rcode fstRead

# Read in Fst data.
# Then add extra columns needed.

fst <- read.csv('data/Chapter3/FstDataCompData.csv')

# Check overlap of datasets.
sum(!(fst$binomial %in% virus2$binomial[virus2$host.species != '']))

notInFst <- fst$binomial[!(fst$binomial %in% virus2$binomial)]
# lots of sp not in virus2. MAybe will include 0 virus species. Kinda makes sense.



#########################################################################################
#### Get distribution size and width                                                 ####
#########################################################################################


#ranges <- ranges[ranges$order_name == 'CHIROPTERA', ]

fst$binomial[!(fst$binomial %in% ranges$binomial)]

fst <- fst[(fst$binomial %in% ranges$binomial), ]

unique(fst$binomial) %>% length




findAreaFst <- function(name){
  #cat(name)
  A <- areaPolygon(ranges[ranges$binomial == as.character(name), ])
  sum(A)
}

fstIucnDistr <- sapply(fst$binomial, findAreaFst)


fst$distrSize <- fstIucnDistr


#### Now get distribution width

findWidth <- function(name){
  #print(name)
  distr <- ranges[ranges$binomial == as.character(name), ]

  coords <- list()
  # Get coordinates from all polygons into one matrix.
  for(i in 1:length(distr@polygons)){
    coords[[i]] <- distr@polygons[[i]]@Polygons[[1]]@coords
  }
  coords <- do.call(rbind, coords)

  # Take the convex hull of coordinates to speed up last step.
  hullCoords <- coords[chull(coords), ]

  maxDist <- max(apply(hullCoords, 1, function(x) distGeo(coords, x)))/1000
  return(maxDist)
  
}

# Calculate widest part of all species distributions.
#   This is slow but also RAM heavy.
#   3 cores doesn't crash my computer with 16GB RAM.
rangeWidth <- mclapply(fst$binomial, findWidth, mc.cores = 3) %>% do.call(c, .)

#rangeWidth <- sapply(fst$binomial, findWidth)

fst$rangeWidth <- rangeWidth
fst$rangeCoverage <- fst$Dmax..km. / fst$rangeWidth



fst$Useable <- fst$rangeCoverage > rangeUseable
sum(fst$Useable, na.rm = TRUE)
fst$binomial[fst$Useable] %>% unique %>% .[!is.na(.)] %>% length

# Need to go back and check data but for now if fst$Useable is na, then it's FALSE (i.e. it's not a useable row)
fst$Useable[is.na(fst$Useable)] <- FALSE


%%end.rcode



%%begin.rcode fstStudyEffort

# First take what data we can from nSpecies analysis.
fstStudy <- sqldf("	
                SELECT fst.binomial, nSpecies.scholarRefs, nSpecies.pubmedRefs
                FROM fst
                LEFT JOIN nSpecies
                ON nSpecies.binomial=fst.binomial
              ")

%%end.rcode

%%begin.rcode fstScrape, eval = runFstScrape

fstNewStudy <- fstStudy[is.na(fstStudy[,2]),1] %>%
                 lapply(., function(x) c(x, scrapeScholar(x), scrapePub(x))) %>%
                 do.call(rbind, .)

names(fstNewStudy) <- c('binomial', 'scholarRefs', 'pubmedRefs')

write.csv(fstNewStudy, file = 'data/Chapter3/fstScrape.csv')

%%end.rcode

%%begin.rcode fstCombine

fstNewStudy <- read.csv('data/Chapter3/fstScrape.csv', row.names = 1)
names(fstNewStudy) <- c('binomial', 'scholarRefs', 'pubmedRefs')

# NAs are from searches with 0 references.
fstNewStudy$pubmedRefs[is.na(fstNewStudy$pubmedRefs)] <- 0

whichRows <- lapply(fstNewStudy$binomial, function(x) which(fstStudy$binomial == x))
for(i in 1:length(whichRows)){
  fstStudy[whichRows[[i]], 2:3] <- fstNewStudy[i, 2:3]
}


fst <- cbind(fst, fstStudy[, 2:3])

# Remove rows whose scale is too small
fst <- fst[fst$Useable, ]


# Don't want rows using mtDNA due to female baised dispersal
fst <- fst[fst$Marker != 'mtDNA', ]

%%end.rcode

%%begin.rcode convertFst

# Nearly all studies use Arlequin.
# Arlequin uses Weir and Cockerham which deal with sample size already.
#   So I don't think I need number of populations.

# Further, the quantity is Number of demes, not number of demes sampled. We have no estimates for n demes and must assume it's large.

# define functions for fst minisatellite and fst allozyme
fstallozyme <- function(fst){
  Nm <- (1 / 4) * (1 / fst - 1)
}

# 
fstmicrosat <- function(fst, pops){
  Nm <- (1 / 4)* (1 / fst - 1) 
}


fst$Nm <- NA
fst$fnc <-NA

microsatBool <- fst$Measure == 'Fst' & fst$Marker == 'microsatellites'
fst$Nm[microsatBool] <- fstmicrosat(fst$Value[microsatBool], fst$nPops[microsatBool])
fst$fnc[microsatBool] <- 'fstmicrosat'

allozymeBool <- fst$Measure == 'Fst' & fst$Marker == 'allozyme'
fst$Nm[allozymeBool] <- fstallozyme(fst$Value[allozymeBool])
fst$fnc[allozymeBool] <- 'fstallozyme'

fst <- fst[!is.na(fst$Nm) & !(fst$Nm == Inf), ]

fstFinal <- fst

# Take means of species with multiple measurements

fstFinal <- fstFinal[!duplicated(fstFinal$binomial), ]
fstFinal$Nm <- sapply(fstFinal$binomial, function(x) mean(fst$Nm[fst$binomial == x]))

# Add number of viruses to fst dataset
#   Includes zeros for species with no known viruses.

fstFinal$virusSpecies <- sapply(fstFinal$binomial, function(x) sum(virus2$binomial == x))




# Add mass data.


mass <- sqldf("
  SELECT [X5.1_AdultBodyMass_g]
  FROM fstFinal
  LEFT JOIN pantheria
  ON fstFinal.binomial=pantheria.MSW05_Binomial
  ")

fstFinal$mass <- mass[, 1]

fstFinal$mass[fstFinal$binomial == 'Myotis ricketti'] <- meanAdditionalMass$mass[meanAdditionalMass$binomial == 'Myotis ricketti']

fstFinal$mass[fstFinal$binomial == 'Myotis macropus'] <- 9.8

fstFinal <- fstFinal[!is.na(fstFinal$mass), ]
%%end.rcode

%%begin.rcode fstCors, fig.show = extraFigs

fstFinal[, c('mass', 'scholarRefs', 'rangeWidth', 'Nm')] %>%
  log %>%
  cbind(virusSpecies = fstFinal$virusSpecies) %>%
  ggpairs(.)


%%end.rcode



%%begin.rcode compareNm, fig.show = extraFigs

ggplot(fstFinal, aes(x = fnc, y = Nm)) +
  geom_point() +
  scale_y_log10()

lm(fstFinal$Nm ~ fstFinal$fnc) %>% aov %>% summary


%%end.rcode


%%begin.rcode fstTree

# Prune the tree for the fst data.

# Which tips are not needed
fstUnneededTips <- tr1$tip.label[!(tr1$tip.label %in% fstFinal$binomial)]

# Prune tree down to only needed tips.
fstTree <- drop.tip(tr1, fstUnneededTips)



%%end.rcode


%%begin.rcode fstTreePlot, out.width = '\\textwidth', fig.cap = 'Pruned phylogeny with dot size showing number of pathogens and colour showing family.', fig.height = 3.6

# Plot tree 
p <- ggtree(fstTree) 

fstFinal$lengthNames <- fstFinal$binomial %>%
                          as.character %>%
                          paste0('  ', .)


p %<+% fstFinal[, c('binomial', 'virusSpecies')] + 
  #geom_tiplab(family = 'lato light', align = FALSE) +
  geom_text(aes(x = x + 15, label = as.character(label)), subset=.(isTip), 
    family = 'Lato light', hjust = 0, size = 3.3) +
  ggplot2::xlim(0, 210) +
  theme_tcdl +
  geom_point(aes(x = x + 8, size = virusSpecies), subset=.(isTip)) +
  scale_size(range = c(0, 4)) +
  theme(legend.key.size = unit(0.8, "lines"),
              legend.text = element_text(size = 9),
              legend.title = element_text(size = 8),
              legend.position = "right",  
              text = element_text(colour = 'darkgrey'),
              legend.key = element_blank()) +
  labs(size = 'Virus Richness') 



%%end.rcode

%%begin.rcode fstRawData, fig.height = 3, fig.cap = 'Gene flow per generation (on a log scale) against viral richness with the genetic marker used shown with colour.'

# Plot raw fstdata
ggplot(fstFinal, aes(x = Nm, y = virusSpecies, colour = Marker)) +
  geom_point(size = 3.5) +
  scale_colour_poke(pokemon = 'oddish', spread = 3) +
  scale_x_log10() +
  xlab('Gene flow (per gen.)') +
  ylab('Viral Richness') #+  geom_smooth(method = 'lm', aes(colour = 'a'))

%%end.rcode






%%begin.rcode fstITanalysis

fstVarList <- c('log(scholarRefs)', 'log(Nm)', 'log(mass)', 'log(distrSize)', 'rand')


fstModelList <- lapply(0:5, function(k) findCombs(k, fstVarList, 5))
fstModelMat <- do.call(rbind, fstModelList)

fstAllFormulae <- apply(fstModelMat[-1, ], 1, function(x) as.formula(paste('virusSpecies ~', paste(x[!is.na(x)], collapse = ' + '))))

fstAllFormulae <- c(as.formula('virusSpecies ~ 1'), fstAllFormulae)

%%end.rcode

%%begin.rcode fstModelSelectBoots, eval = fstBoots


fstModelSelect <- function(allForm, data, phy, boot, allModelMat, varList){
  
  set.seed(paste0('22311', boot))
  bootData <- cbind(data, rand = runif(nrow(data)))
  rownames(bootData) <- bootData$binomial
  #compBootData <- comparative.data(data = bootData, phy = phy, names.col = 'binomial')

  results <- apply(allModelMat, 1, function(x) sapply(varList, function(y) y %in% x)) %>%
               t %>%
               data.frame %>%
               cbind(AIC = NA, boot = boot, lambda = NA, attempt = NA, predictors = NA)



  for(m in 1:length(allForm)){
    if(exists('model')){
      rm(model)
    }
    try({
      model <- gls(allForm[[m]], correlation = corPagel(value = 0.4, phy = phy), data = bootData, method = 'ML')  
      results$attempt[m] <- 1
    }) 
    if(!exists('model')){
      try({
        model <- gls(allForm[[m]], correlation = corPagel(value = 0.3, phy = phy), data = bootData, method = 'ML')  
        results$attempt[m] <- 2
      }) 
    }
    if(!exists('model')){
      try({
        model <- gls(allForm[[m]], correlation = corPagel(value = 0.2, phy = phy), data = bootData, method = 'ML')  
        results$attempt[m] <- 3
      }) 
    }
    if(!exists('model')){
      try({
        model <- gls(allForm[[m]], correlation = corPagel(value = 0.1, phy = phy), data = bootData, method = 'ML')  
        results$attempt[m] <- 4
        message('Running lm')
      }) 
    }
    if(!exists('model')){
      try({
        model <- lm(allForm[[m]], data = bootData) 
        results$attempt[m] <- 5
        message('Running lm')
      }) 
    }
    #model <- lm(allForm[[m]], data = bootData)
    #model <- pgls(allForm[[m]], data = compBootData, lambda = 'ML')


    results$AIC[m] <- AICc(model)
    results$predictors[m] <- allForm[[m]] %>% as.character %>% .[3]
    if(inherits(model, 'gls')){
        results$lambda[m] <- model$modelStruct$corStruct[1]
    }
    message(paste('Boot:', boot, ', m:', m, '\n'))
  }

  results$dAIC <- results$AIC - min(results$AIC)
  results$weight <- exp(- 0.5 * results$dAIC) / sum(exp(- 0.5 * results$dAIC))


  return(results)

}


fstModelsBootStrap <- mclapply(1:nBoots, function(b) fstModelSelect(fstAllFormulae, fstFinal, fstTree, b, fstModelMat, fstVarList), mc.cores = nCores)

fstAllResults <- do.call(rbind, fstModelsBootStrap)

write.csv(fstAllResults, file = 'data/Chapter3/fstModelSelectSubspecies.csv')


%%end.rcode

%%begin.rcode fstAnalyseModelSelect, fig.show = extraFigs

fstAllResults <- read.csv('data/Chapter3/fstModelSelectSubspecies.csv', row.names = 1)

fstSepVarWeights <- lapply(1:nBoots, function(b) 
                      sapply(names(fstAllResults)[1:5], 
                        function(x) 
                          sum(fstAllResults[fstAllResults$boot == b, 'weight'][fstAllResults[fstAllResults$boot == b, x]])
                      )
                     )      

fstSepVarWeights <- do.call(rbind, fstSepVarWeights) %>%
                      data.frame(., boot = 1:nBoots) %>%
                      reshape2::melt(., value.name = 'estimate', id.vars = 'boot')

fstSepVarWeights$col <- 'Other Variables'
fstSepVarWeights$col[fstSepVarWeights$variable == 'log.Nm.'] <- 'Population Structure'
fstSepVarWeights$col[fstSepVarWeights$variable == 'rand'] <- 'Null'


fstVarWeights <- sapply(names(fstAllResults)[1:5], function(x) sum(fstAllResults$weight[fstAllResults[, x]])/nBoots)


fstModelWeights <- fstAllResults %>%
                  group_by(predictors) %>%
                  summarise(AICc = mean(AIC)) %>%
                  mutate(dAIC = AICc - min(AICc), modelWeight = exp(- 0.5 * dAIC) / sum(exp(- 0.5 * dAIC))) %>%
                  arrange(desc(modelWeight)) %>%
                  mutate(cumulativeWeight = cumsum(modelWeight)) 




%%end.rcode


%%begin.rcode fstITPlots, fig.cap = "Akaika variable weights for $F_{ST}$ analysis. The probability that each variable will be in the best model if the data were recollected is shown for each of the bootstrap analyses. The purple ``Null'' box is a uniform random variable used as a null. Population structure ($F_{ST}$), shown in red, is much less likely to be in the best model than this random variable.", fig.height = 3.9, fig.scap = 'Akaika variable weights for $F_{ST}$ analysis.'

ggplot(fstSepVarWeights, aes(x = variable, y = estimate, colour = col, fill = col)) +
  geom_boxplot(outlier.colour = grey(0.3), notch = FALSE, notchwidth = 0.7) +
  scale_colour_manual(values = pokepal('nidorino')[c(2, 5, 11)]) +
  scale_fill_manual(values = pokepal('nidorino')[c(3, 6, 10)]) +
  theme(legend.position = 'none', axis.text.x = element_text(size = 15, angle = 45, hjust = 1)) +
  scale_x_discrete(labels = c('Study Effort', 'Gene Flow', 'Mass', 'Range Size', 'Null'))+
  ylab('P(in best model)') +
  xlab('')





%%end.rcode


%%begin.rcode fstITlambda, fig.show = extraFigs, fig.cap = 'Values of $\\lambda$ found in $F_{ST}$ analysis.', fig.height = 3

ggplot(fstAllResults, aes(x = lambda)) + 
  geom_histogram() +
  ylab('Count') +
  xlab(expression(paste('Phylogenetic Signal, ', lambda)))

%%end.rcode


%%begin.rcode fstITlambdaFacets, fig.show = extraFigs, fig.height = 4


transform(fstAllResults, log.mass. = c('Other', 'Mass' )[factor(log.mass.)]) %>%
ggplot(aes(x = lambda)) + 
  facet_grid(. ~ log.mass.) +
  geom_histogram() +
  ylab('Count') +
  xlab(expression(paste('Phylogenetic Signal, ', lambda)))


transform(fstAllResults, log.Nm. = c('Other', 'Nm' )[factor(log.Nm.)]) %>%
ggplot(aes(x = lambda)) + 
  facet_grid(. ~ log.Nm.) +
  geom_histogram() +
  ylab('Count') +
  xlab(expression(paste('Phylogenetic Signal, ', lambda)))


transform(fstAllResults, log.distrSize. = c('Other', 'distrSize' )[factor(log.distrSize.)]) %>%
ggplot(aes(x = lambda)) + 
  facet_grid(. ~ log.distrSize.) +
  geom_histogram() +
  ylab('Count') +
  xlab(expression(paste('Phylogenetic Signal, ', lambda)))


transform(fstAllResults, log.scholarRefs. = factor(c('Scholar Refs', 'Other')[factor(!log.scholarRefs.)], levels = c('Scholar Refs', 'Other'))) %>%
ggplot(aes(x = lambda)) + 
  facet_grid(. ~ log.scholarRefs.) +
  geom_histogram() +
  ylab('Count') +
  xlab(expression(paste('Phylogenetic Signal, ', lambda)))

transform(fstAllResults, rand = c('Other', 'Rand' )[factor(rand)]) %>%
ggplot(aes(x = lambda)) + 
  facet_grid(. ~ rand) +
  geom_histogram() +
  ylab('Count') +
  xlab(expression(paste('Phylogenetic Signal, ', lambda)))


%%end.rcode

%%begin.rcode lookAtLambda, fig.show = extraFigs

fstComp <- comparative.data(fstTree, fstFinal, 'binomial')

fullFst <- pgls(virusSpecies ~ log(Nm) + log(mass) + log(distrSize) + log(distrSize) + log(scholarRefs), fstComp, lambda = 'ML')

fst.lambda.profile <- pgls.profile(fullFst, "lambda")
plot(fst.lambda.profile)

data.frame(x = fst.lambda.profile$x, L = fst.lambda.profile$logLik) %>%
ggplot(aes(x, L)) +
  geom_line() +
  geom_vline(xintercept = fst.lambda.profile$ci$ci.val, col = 'steelblue')


%%end.rcode


%%begin.rcode fstVIF
sqrt(vif(lm(virusSpecies ~ log(scholarRefs) + Nm +  log(mass) + log(distrSize), data = fstFinal)))

%%end.rcode

$F_{ST}$ studies are conducted at a range of spatial scales, but $F_{ST}$ often increases with distance studied \cite{}.
To minimise the effects of this I only used data from studies that cover \rinline{rangeUseable * 100}\% of the diameter of the species range.
This is a largely arbitrary value that could be considered to reflect a `global' estimate of $F_{ST}$ while keeping a reasonable number of datapoints available.
I calculated the diameter of the species range by finding the furthest apart points in the IUCN species range \cite{} even if the range is split into multiple polygons.
The width covered by each study was the distance between the most distant sampling sites.
When this was not explicit in the paper, the centre of the lowest level of geographic area was used.



\subsection{Statistical analysis}

Statistical analysis for both dependant variables were conducted using a information theory/model averaging approach \cite{burnham2002model} specifically following \cite{whittingham2005habitat, whittingham2006we}.
I chose a credible set of models including all combinations of independent variables.
In the analysis using the number of subspecies dependant variable I also included an interaction term between study effort and number of subspecies as I believe \emph{a priori} that this interaction may be present.
The interaction was only included in models with both study effort and number of subspecies as an individual term.

I fitted phylogenetic regressions using caper \cite{nlme} to all models.
In each case I simultaneously fitted the $\lambda$ parameter as this avoids mispecifying the model \cite{revell2010phylogenetic}.
$\kappa$ and $\delta$ were constrained to one.

As the number of data points is close to or much less than the number of variables times 40 I calculated small sample corrected AIC (AICc) for each model and then calculated Akaiki weights.
This value can be interpreted as the probability that a model would be the best model if the data were recollected.
For each variable, the sum of the Akaiki weights for models containing that variable are summed.
This value can be interpreted as the probability that the given variable is in the best model.
Following \cite{whittingham2005habitat} I included a uniformally random variable as a null variable as even unimportant variables can have Akaiki weights significantly greater than zero.
The whole analysis was run \rinline{nBoots} times, resampling the random variable each time.
We calculated $\bar{AICc}$ by averaging AICc scores within models.
$\Delta\text{AICc}$ was calculated as $\text{min}(\bar{AICc}) - \bar{AICc}$, not the mean of the individual $\Delta\text{AICc}$ scores, to guarantee that the best model has $\Delta\text{AICc} = 0$.


Plots were created with a combination of \cite{ggplot2, palettetown, dotwhisker, ggtree}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\section{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Number of Subspecies}
\tmpsection{More descriptive}

After data cleaning there was data for \rinline{nrow(nSpecies)} bat species in \rinline{length(unique(nSpecies$Family))} families.
The number of described virus species for a bat host ranged up to \rinline{max(nSpecies$virusSpecies)} viruses in \emph{\rinline{nSpecies$binomial[which.max(nSpecies$virusSpecies)]}}.
Figure~\ref{fig:treePlot} shows the phylogeny used and the number of viruses for each species.
The mean number of viruses across families is fairly constant with a lower range of \rinline{min(familyMeans$mean)} for \rinline{familyMeans$Family[which.min(familyMeans$mean)]}.
The highest mean is \rinline{familyMeans$Family[which.max(familyMeans$mean)]} with \rinline{max(familyMeans$mean)} virus species per bat species, but this is based on a sample size of \rinline{familyMeans$n[which.max(familyMeans$mean)]}.
The \rinline{familyMeans$Family[order(familyMeans$mean, decreasing = TRUE)[2]]} have the second highest mean (n = \rinline{familyMeans$n[order(familyMeans$mean, decreasing = TRUE)[2]]}) of \rinline{familyMeans$mean[order(familyMeans$mean, decreasing = TRUE)[2]]}.

The small change in mean pathogen richness across families and the lack of clear pattern in Figure~\ref{fig:treePlot} implies that viral richness is not strongly phylogenetic. 
This is corroborated by the small estimated size of $\lambda$ ($\lambda$ = \rinline{virusLambda$param['lambda']}, $p$ = \rinline{virusLambda$param.CI$lambda$bounds.p[1]}).
This fact implies that other factors must control pathogen richness.
It also implies that pathogens are not directly inherited down the phylogeny, although this is to be expected by the fast evolution of viruses.

Of the explanatory variables, the number of subspecies has no phylogenetic autocorrelation ($\lambda$ = \rinline{sspLambda$param['lambda']}, $p$ = \rinline{sspLambda$param.CI$lambda$bounds.p[1]}), study effort and distribution size have weak but significant autocorrelation (Study Effort: $\lambda$ = \rinline{scholarLambda$param['lambda']}, $p$ = \rinline{scholarLambda$param.CI$lambda$bounds.p[1]}, Distribution size: $\lambda$ = \rinline{distrLambda$param['lambda']}, $p$ = \rinline{distrLambda$param.CI$lambda$bounds.p[1]}) and mass is strongly phylogenetic ($\lambda$ = \rinline{massLambda$param['lambda']}, $p$ = \rinline{massLambda$param.CI$lambda$bounds.p[1]}).

\tmpsection{Model results}
%See Figure \ref{fig:plotSubspeciesCoefs} for a display of estimated coefficients for the two models using number of viruses as the response variable. 
%The main model with mass, study effort and number of subspecies as predictors found study effort to be highly significant ($\beta = $ \rinline{subspeciesJoint$model$coef['log(pubmedRefs + 1)']}, $p = $ \rinline{subJoint.summary$coefficients[2,'Pr(>|t|)']}). 
%The number of subspecies was marginally significant ($\beta = $ \rinline{ subspeciesJoint$model$coef['NumberOfSubspecies']}, $p = $ \rinline{subJoint.summary$coefficients[3,'Pr(>|t|)']}). 
%The effect of nonindependance due to phylogeny was very small ($\lambda = $ \rinline{subJoint.summary$param['lambda']}, $p = $ \rinline{subspeciesJoint$param.CI$lambda$bounds.p[1]}).

%The interaction term between study effort and number of subspecies, when included, was significant ($\beta = $ \rinline{ subspeciesInter$model$coef['NumberOfSubspecies:log(scholarRefs)']}, $p = $ \rinline{subInter.summary$coefficients[5,'Pr(>|t|)']}).



\subsection{$F_{ST}$}

%%begin.rcode dwplotCap
dwplotCap <- '
Plot of coefficient estimates and 95\\% confidence intervals for phylogenetic model with and without interactions between study effort and number of subspecies. 
Without interactions, number of subspecies is significant.
'

%%end.rcode

%%begin.rcode plotSubspeciesCoefs, fig.cap = dwplotCap, fig.height = 2, fig.show = extraFigs


subspeciesCoefs <- data.frame(
  estimate = c(subspeciesJointUnlog$model$coef, subspeciesInter$model$coef),
  std.error = c(subspeciesJointUnlog$sterr, subspeciesInter$sterr),
  term = names(c(subspeciesJointUnlog$model$coef, subspeciesInter$model$coef)),
  model = rep(c('joint', 'inter'), 
    c(length(subspeciesJointUnlog$model$coef), length(subspeciesInter$model$coef)))
)

x <- rbind(subspeciesCoefs, 
  c(NA, NA, 'NumberOfSubspecies:log(scholarRefs)', 'joint')) %>%
  filter(term != '(Intercept)') %>%
  arrange(model, term) 

x$term <- plyr::mapvalues(x$term, from = levels(x$term)[2:5], 
  to = c('Mass', 'Cites', 'Subspecies', 'Cites*Subspecies'))



dwplot(x) +
  theme(legend.position="right",
        axis.text.y = element_text(color = "black", size = 13, family  =  "Lato Light", vjust = 0.3)) +
  scale_colour_manual(values = pokepal('Nidorina')[c(4, 10)], 
    labels = c('Interaction', 'No Interaction'), name = 'Model') +
  xlab('Coefficient Estimate')
    
%%end.rcode

%%begin.rcode tableParams


#tableV <- c(coef(subspeciesJointUnlog)['(Intercept)'], 
#            coef(subspeciesJointUnlog)['(Intercept)'] - 1.96 * (summary(subspeciesJointUnlog))$coefficients['(Intercept)', 'Std. Error'],
#            coef(subspeciesJointUnlog)['(Intercept)'] + 1.96 * (summary(subspeciesJointUnlog))$coefficients['(Intercept)', 'Std. Error'],
#            (summary(subspeciesJointUnlog))$coefficients['(Intercept)', 'Pr(>|t|)'],

#            coef(subspeciesJointUnlog)['NumberOfSubspecies'], 
#            coef(subspeciesJointUnlog)['NumberOfSubspecies'] - 1.96 * (summary(subspeciesJointUnlog))$coefficients['NumberOfSubspecies', 'Std. Error'],
#            coef(subspeciesJointUnlog)['NumberOfSubspecies'] + 1.96 * (summary(subspeciesJointUnlog))$coefficients['NumberOfSubspecies', 'Std. Error'],
#            (summary(subspeciesJointUnlog))$coefficients['NumberOfSubspecies', 'Pr(>|t|)'],


#            coef(subspeciesJointUnlog)['log(mass)'], 
#            coef(subspeciesJointUnlog)['log(mass)'] - 1.96 * (summary(subspeciesJointUnlog))$coefficients['log(mass)', 'Std. Error'],
#            coef(subspeciesJointUnlog)['log(mass)'] + 1.96 * (summary(subspeciesJointUnlog))$coefficients['log(mass)', 'Std. Error'],
#            (summary(subspeciesJointUnlog))$coefficients['log(mass)', 'Pr(>|t|)'],

#            coef(subspeciesJointUnlog)['log(scholarRefs)'], 
#            coef(subspeciesJointUnlog)['log(scholarRefs)'] - 1.96 * (summary(subspeciesJointUnlog))$coefficients['log(scholarRefs)', 'Std. Error'],
#            coef(subspeciesJointUnlog)['log(scholarRefs)'] + 1.96 * (summary(subspeciesJointUnlog))$coefficients['log(scholarRefs)', 'Std. Error'],
#            (summary(subspeciesJointUnlog))$coefficients['log(scholarRefs)', 'Pr(>|t|)']
#)

#tableM <- matrix(tableV, ncol = 4, nrow = 4, byrow = TRUE)


%%end.rcode





%\begin{table}[t]
%  \rowcolors{2}{gray!25}{white}
%  \begin{tabular}{lrr}
% \hline
%  Covariate & Estimate (95\% CI) & $p$ value\\
%  \hline
%  Number of subspecies & \rinline{tableM[2,1]} (\rinline{tableM[2, 2]} -- \rinline{tableM[2, 3]}) & \rinline{tableM[2, 4]}\\
%  Mass & \rinline{tableM[3,1]} (\rinline{tableM[3, 2]} -- \rinline{tableM[3, 3]}) & \rinline{tableM[3, 4]}\\
%  Study effort & \rinline{tableM[4,1]} (\rinline{tableM[4, 2]} -- \rinline{tableM[4, 3]}) & \rinline{tableM[4, 4]}\\
%  Intercept & \rinline{tableM[1,1]} (\rinline{tableM[1, 2]} -- \rinline{tableM[1, 3]}) & \rinline{tableM[1, 4]}\\
%  \end{tabular}
%\caption{Table of parameter estimates.}
%\label{t:params}
%\end{table}


\begin{table}[t]
\rowcolors{2}{gray!25}{white}
\begin{tabular}{>{\small}lrrrr}

\normalsize{Model} & $\bar{\text{AICc}}$ & $\Delta$AICc & $w_i$ & $\sum w_i$\\
\hline
log(Scholar)*NSubspecies + rand & 
\rinline{round(modelWeights[1 ,2])} & \rinline{sprintf("%.2f", round(modelWeights[1, 3], 2))} &
\rinline{sprintf("%.2f", round(modelWeights[1, 4], 2))} & \rinline{sprintf("%.2f", round(modelWeights[1, 5], 2))}\\
log(Scholar)*NSubspecies & 
\rinline{round(modelWeights[2 ,2])} & \rinline{sprintf("%.2f", round(modelWeights[2, 3], 2))} &
\rinline{sprintf("%.2f", round(modelWeights[2, 4], 2))} & \rinline{sprintf("%.2f", round(modelWeights[2, 5], 2))}\\
log(Scholar)*NSubspecies + rand + log(Mass) & 
\rinline{round(modelWeights[3 ,2])} & \rinline{sprintf("%.2f", round(modelWeights[3, 3], 2))} &
\rinline{sprintf("%.2f", round(modelWeights[3, 4], 2))} & \rinline{sprintf("%.2f", round(modelWeights[3, 5], 2))}\\
log(Scholar)*NSubspecies  + log(Mass) & 
\rinline{round(modelWeights[4 ,2])} & \rinline{sprintf("%.2f", round(modelWeights[4, 3], 2))} &
\rinline{sprintf("%.2f", round(modelWeights[4, 4], 2))} & \rinline{sprintf("%.2f", round(modelWeights[4, 5], 2))}\\
log(Scholar)*NSubspecies  + log(Mass) + log(RangeSize) & 
\rinline{round(modelWeights[5 ,2])} & \rinline{sprintf("%.2f", round(modelWeights[5, 3], 2))} &
\rinline{sprintf("%.2f", round(modelWeights[5, 4], 2))} & \rinline{sprintf("%.2f", round(modelWeights[5, 5], 2))}\\
log(Scholar)*NSubspecies  + rand + log(RangeSize) & 
\rinline{round(modelWeights[6 ,2])} & \rinline{sprintf("%.2f", round(modelWeights[6, 3], 2))} &
\rinline{sprintf("%.2f", round(modelWeights[6, 4], 2))} & \rinline{sprintf("%.2f", round(modelWeights[6, 5], 2))}\\
log(Scholar)*NSubspecies  + log(RangeSize) & 
\rinline{round(modelWeights[7 ,2])} & \rinline{sprintf("%.2f", round(modelWeights[7, 3], 2))} &
\rinline{sprintf("%.2f", round(modelWeights[7, 4], 2))} & \rinline{sprintf("%.2f", round(modelWeights[7, 5], 2))}\\
log(Scholar) + NSubspecies & 
\rinline{round(modelWeights[8 ,2])} & \rinline{sprintf("%.2f", round(modelWeights[8, 3], 2))} &
\rinline{sprintf("%.2f", round(modelWeights[8, 4], 2))} & \rinline{sprintf("%.2f", round(modelWeights[8, 5], 2))}\\
log(Scholar) + NSubspecies + log(Mass) & 
\rinline{round(modelWeights[9 ,2])} & \rinline{sprintf("%.2f", round(modelWeights[9, 3], 2))} &
\rinline{sprintf("%.2f", round(modelWeights[9, 4], 2))} & \rinline{sprintf("%.2f", round(modelWeights[9, 5], 2))}
\end{tabular}
\caption[Model selection results for number of subspecies analysis]{
Model selection results for number of subspecies analysis. 
$\bar{\text{AICc}}$ is the mean AICc score across \rinline{nBoots} resamplings of the null random variable. 
$\Delta$AICc is the $\bar{\text{AICc}}$ score minus the lowest score. 
$w_i$ is the Akaike weight and can be interpreted as the probability that the model is the best model (of those in the plausible set).
$\sum w_i$ is the cumulative sum of the Akaike weights.}
\label{t:subsmodels}
\end{table}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\section{Discussion}  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







%%begin.rcode rm1virTests
# Want to look at whether the species with only 1 virus are just an artifact and whether they strongly affec the analysis.

rm1df <- cbind(nSpecies, oneVir = nSpecies$virusSpecies > 1)
rm1compData <- comparative.data(data = rm1df, phy = pruneTree, names.col = 'binomial')


# t.test for Scholar. Approx. normal and good to have confidence intervals of diff mean.
# p = 3e-9 diff (95%) = 0.86 +- 0.13
scholarTest <- pgls(log(scholarRefs) ~ oneVir, data = rm1compData, lambda = 'ML')

summary(scholarTest)
par(mfrow = c(2,2))
#plot(scholarTest)


# Wilcox test to compare means of mass (certainly not normally distributed)
# p = 0.09. 
massTest <-  pgls(log(mass) ~ oneVir, data = rm1compData, lambda = 'ML')

summary(massTest)

#plot(massTest)

# p = 2e-4. 
subspeciesTest <-  pgls(NumberOfSubspecies ~ oneVir, data = rm1compData, lambda = 'ML')

summary(subspeciesTest)
#plot(subspeciesTest)
%%end.rcode

%%begin.rcode rm1virCapt

rm1virCapt <- c(
paste0(
'Density curves for mass of bat species with 1 or > 1 pathogen species.
The hump of the \\emph{Pteropodidae} (large fruit bats) can be seen.
It seems likely that this family are overstudied as they carry a number of important zoonotics.
(pgls: p = ', round((anova(massTest))$P[1], 3), ')') ,
paste0(
'Density curves for number of subspecies of bat species with 1 or > 1 pathogen species.
(pgls: p = ',
round((anova(subspeciesTest))$P[1], 5), ')'),
'Density curves for number of pubmed references of bat species with 1 or > 1 pathogen species.
There is a clear trend that many species with only 1 virus species, have 0 pubmed references.
',
paste0(
'Density curves for number of scholar references of bat species with 1 or > 1 pathogen species.
The strong trend in the pubmed data is not noticeable here.
(pgls: p = ', round((anova(scholarTest))$P[1], 5), ')')
)

rm1virCaptTitle <- c(
  'Density of mass variable for 1 or >1 viruses.',
  'Density of number of subspecies 1 or >1 viruses.',
  'Density of number of pubmed references 1 or >1 viruses.',
  'Density of number of scholar references 1 or >1 viruses.'    
)

%%end.rcode


%%begin.rcode rm1vir, fig.show = extraFigs, fig.cap = rm1virCapt, fig.scap = rm1virCaptTitle
# Plots to compare data for species with >1 virus and species with =1 virus.

ggplot(nSpecies, aes(x = mass, fill = virusSpecies > 1)) + 
  geom_density(alpha = 0.4) +
  scale_x_log10()

ggplot(nSpecies, aes(x = NumberOfSubspecies, fill = virusSpecies > 1)) + 
  geom_density(alpha = 0.4) +
  scale_x_log10()

ggplot(nSpecies, aes(x = pubmedRefs + 1, fill = virusSpecies > 1)) + 
  geom_density(alpha = 0.4) +
  scale_x_log10()


ggplot(nSpecies, aes(x = scholarRefs, fill = virusSpecies > 1)) + 
  geom_density(alpha = 0.4) +
  scale_x_log10()

%%end.rcode


%%begin.rcode phyloRM1vir

# Remove species with =1 virus and refit models.

compRm1Vir <- comparative.data(data = nSpecies[nSpecies$virusSpecies > 1, ], 
                               phy = pruneTree, names.col = 'binomial')

# Subspecies p = 0.24. Loses significance.
# n = 84
# R^2 similar to model with all species.
unlogRm1 <- pgls(
  virusSpecies ~ log(scholarRefs) + NumberOfSubspecies +  log(mass), 
  data = compRm1Vir, lambda = 'ML')

unlogRm1.summary <- summary(unlogRm1)

# Subspecies p = 0.057. Marginal.
logRm1 <- pgls(
  virusSpecies ~ log(scholarRefs) + log(NumberOfSubspecies) +  log(mass), 
  data = compSubspecies, lambda = 'ML')

logRm1.summary <- summary(logRm1)


%%end.rcode
\clearpage


%%begin.rcode rm1virresults, echo = FALSE, results = 'hide'

# Models with species with only 1 virus removed

# Unlogged subspecies variable
unlogRm1.summary

# logged subspecies variable
logRm1.summary

%%end.rcode



%%begin.rcode OneorMoreVirCapt
OneorMoreVirCapt <- 'Number of subspecies by log study effort with colour indicating whether a species has 1 or more than 1 known virus species.
There does not seem to be a huge difference.
Species with many references often have many subspecies as expected.
Species with many references, have more subspecies per effort if they have multiple viruses.'

OneorMoreVirCaptTitle <- 'Number of subspecies by study effort'

%%end.rcode 

%%begin.rcode OneorMoreVir, fig.show = extraFigs, fig.cap = OneorMoreVirCapt, fig.scap = OneorMoreVirCaptTitle

nSpecies$scholarBins <- cut(log(nSpecies$scholarRefs), 8)

ggplot(nSpecies, 
  aes(y = NumberOfSubspecies, x = scholarRefs, colour = virusSpecies > 1)) +
  geom_point() +
  scale_x_log10()


ggplot(nSpecies, 
  aes(y = NumberOfSubspecies, x = scholarBins, colour = virusSpecies > 1, fill = virusSpecies > 1)) +
  geom_boxplot() +
  scale_colour_manual(values = pokepal('Charizard')[c(4,7)]) +
  scale_fill_manual(values = pokepal('Charizard')[c(14, 9)])


%%end.rcode


%%begin.rcode pubmedresidPlot, fig.show = extraFigs,  fig.cap = 'Plot using residuals from number of viruses against number of citations (study effort). Nonphylogenetic trend line added. '


ggplot(nSpecies, aes(y = pubmedResid, x = log(NumberOfSubspecies))) + 
  geom_point(aes(colour = familyPlotCol)) +
  geom_smooth(method = 'lm') +
  labs(colour = 'Family') +
  scale_colour_hc()

%%end.rcode





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Repeat analysis with bat clocks and rocks                  %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Appendix}



%%begin.rcode treeRead2

# Read in trees
t2 <- read.nexus('data/Chapter3/BatST2BL.nex')

# Make names match previous names
t2$tip.label <- gsub('_', ' ', t2$tip.label)


unneededTips2 <- t2$tip.label[!(t2$tip.label %in% nSpecies$binomial)]

# Prune tree down to only needed tips.
pruneTree2 <- drop.tip(t2, unneededTips2)


nSpecies2 <- sapply(pruneTree2$tip.label, function(x) which(nSpecies$binomial == x)) %>%
               nSpecies[., ]


################
## Fst tree   ##
################


# Which tips are not needed
fstUnneededTips2 <- t2$tip.label[!(t2$tip.label %in% fstFinal$binomial)]

# Prune tree down to only needed tips.
fstTree2 <- drop.tip(t2, fstUnneededTips2)

# Which tips in Fst analysis are not in bats clocks tree.
fstFinal$binomial[!(fstFinal$binomial %in% fstTree2$tip.label)]


# Hacky cruddy way of placing the missing tips into the tree. Should end up with genus level polytomies in trimmed tree.
# Just replacing some of the uneeded tips with the ones I need.

t2$tip.label[t2$tip.label == 'Miniopterus pusillus'] <- 'Miniopterus natalensis'
t2$tip.label[t2$tip.label == 'Miniopterus schreibersi'] <- 'Miniopterus schreibersii'
t2$tip.label[t2$tip.label == 'Rousettus celebensis'] <- 'Rousettus leschenaultii'
t2$tip.label[t2$tip.label == 'Myotis oxyotus'] <- 'Myotis macropus'


#Re prune tree
# Which tips are not needed
fstUnneededTips2 <- t2$tip.label[!(t2$tip.label %in% fstFinal$binomial)]

# Prune tree down to only needed tips.
fstTree2 <- drop.tip(t2, fstUnneededTips2)

# Check we now have all the tips.
fstFinal$binomial[!(fstFinal$binomial %in% fstTree2$tip.label)]

rm(t2)




%%end.rcode


%%begin.rcode treePlot2, show.figs = extraFigs, out.width = '\\textwidth', fig.cap = 'Pruned phylogeny \\cite{jones2005bats} with dot size showing number of pathogens and colour showing family.'

# Plot tree 
p2 <- ggtree(pruneTree2, layout = 'fan') 

p2 %<+% nSpecies2[, 1:6] +
  geom_point(aes(size = virusSpecies, colour = Family), subset=.(isTip)) +
  scale_size(range = c(0.8, 3)) +
  scale_colour_manual(values = c(pokepal('oddish')[c(1,3,5,6,9,10)],    pokepal('Carvanha')[c(1,2,4, 13, 12)])) +
  theme_tcdl +
  theme(plot.margin = unit(c(-1, 3, -2.5, -2), "lines")) +
  theme(legend.position = 'right') +
  labs(size = 'Virus Richness') +
  theme(legend.key.size = unit(0.6, "lines"),
              legend.text = element_text(size = 6),
              legend.title = element_text(size = 8))



%%end.rcode



%%begin.rcode runBatClocks, eval = batclocksBoots


modelSelect2 <- function(allForm, data, phy, boot, allModelMat, varList){
  
  set.seed(paste0('1993', boot))
  bootData <- cbind(data, rand = runif(nrow(data)))
  rownames(bootData) <- bootData$binomial
  #compBootData <- comparative.data(data = bootData, phy = phy, names.col = 'binomial')

  results <- apply(allModelMat, 1, function(x) sapply(c(varList, "log(scholarRefs):NumberOfSubspecies"), function(y) y %in% x)) %>%
               t %>%
               data.frame %>%
               cbind(AIC = NA, boot = boot, lambda = NA)



  for(m in 1:length(allForm)){
    if(exists('model')){
      rm(model)
    }
    try({
      model <- gls(allForm[[m]], correlation = corPagel(value = 0.4, phy = phy), data = bootData, method = 'ML')  
      results$attempt[m] <- 1
    }) 
    if(!exists('model')){
      try({
        model <- gls(allForm[[m]], correlation = corPagel(value = 0.3, phy = phy), data = bootData, method = 'ML')  
        results$attempt[m] <- 2
      }) 
    }
    if(!exists('model')){
      try({
        model <- gls(allForm[[m]], correlation = corPagel(value = 0.2, phy = phy), data = bootData, method = 'ML')  
        results$attempt[m] <- 3
      }) 
    }
    if(!exists('model')){
      try({
        model <- gls(allForm[[m]], correlation = corPagel(value = 0.1, phy = phy), data = bootData, method = 'ML')  
        results$attempt[m] <- 4
        message('Running lm')
      }) 
    }
    if(!exists('model')){
      try({
        model <- lm(allForm[[m]], data = bootData) 
        results$attempt[m] <- 5
        message('Running lm')
      }) 
    }
    #model <- lm(allForm[[m]], data = bootData)
    #model <- pgls(allForm[[m]], data = compBootData, lambda = 'ML')


    results$AIC[m] <- AICc(model)
    results$predictors[m] <- allForm[[m]] %>% as.character %>% .[3]
    if(inherits(model, 'gls')){
        results$lambda[m] <- model$modelStruct$corStruct[1]
    }
    message(paste('Boot:', boot, ', m:', m, '\n'))
  }

  results$dAIC <- results$AIC - min(results$AIC)
  results$weight <- exp(- 0.5 * results$dAIC) / sum(exp(- 0.5 * results$dAIC))


  return(results)

}


fitModelsBootStrap2 <- mclapply(1:nBoots, function(b) modelSelect2(allFormulae, nSpecies2, pruneTree2, b, allModelMat, varList), mc.cores = nCores)

allResults2 <- do.call(rbind, fitModelsBootStrap2)

write.csv(allResults2, file = 'data/Chapter3/modelSelectSubspeciesBatClocks.csv')


## FST analysis

fstModelsBootStrap2 <- mclapply(1:nBoots, function(b) fstModelSelect(fstAllFormulae, fstFinal, fstTree2, b, fstModelMat, fstVarList), mc.cores = nCores)

fstAllResults2 <- do.call(rbind, fstModelsBootStrap2)

write.csv(fstAllResults2, file = 'data/Chapter3/fstModelSelectSubspeciesBatClocks.csv')


%%end.rcode


%%begin.rcode batClocksAnalyse


allResults2 <- read.csv('data/Chapter3/modelSelectSubspeciesBatClocks.csv', row.names = 1)

varWeights2 <- sapply(names(allResults2)[1:6], function(x) sum(allResults2$weight[allResults2[, x]])/nBoots)


sepVarWeights2 <- lapply(1:nBoots, function(b) 
                      sapply(names(allResults2)[1:6], 
                        function(x) 
                          sum(allResults2[allResults2$boot == b, 'weight'][allResults2[allResults2$boot == b, x]])
                      )
                     )      

sepVarWeights2 <- do.call(rbind, sepVarWeights2) %>%
                      data.frame(., boot = 1:nBoots) %>%
                      reshape2::melt(., value.name = 'estimate', id.vars = 'boot')

sepVarWeights2$col <- 'Other Variables'
sepVarWeights2$col[grep('NumberOf', sepVarWeights2$variable)] <- 'Population Structure'
sepVarWeights2$col[sepVarWeights2$variable == 'rand'] <- 'Null'



modelWeights2 <- allResults2 %>%
                  group_by(predictors) %>%
                  summarise(AICc = mean(AIC)) %>%
                  mutate(dAIC = AICc - min(AICc), modelWeight = exp(- 0.5 * dAIC) / sum(exp(- 0.5 * dAIC))) %>%
                  arrange(desc(modelWeight)) %>%
                  mutate(cumulativeWeight = cumsum(modelWeight)) %>%
                  mutate(string = levels(predictors)[predictors])


#### FST


fstAllResults2 <- read.csv('data/Chapter3/fstModelSelectSubspeciesBatClocks.csv', row.names = 1)

fstSepVarWeights2 <- lapply(1:nBoots, function(b) 
                      sapply(names(fstAllResults2)[1:5], 
                        function(x) 
                          sum(fstAllResults2[fstAllResults2$boot == b, 'weight'][fstAllResults2[fstAllResults2$boot == b, x]])
                      )
                     )      

fstSepVarWeights2 <- do.call(rbind, fstSepVarWeights2) %>%
                      data.frame(., boot = 1:nBoots) %>%
                      reshape2::melt(., value.name = 'estimate', id.vars = 'boot')

fstSepVarWeights2$col <- 'Other Variables'
fstSepVarWeights2$col[fstSepVarWeights2$variable == 'log.Nm.'] <- 'Population Structure'
fstSepVarWeights2$col[fstSepVarWeights2$variable == 'rand'] <- 'Null'


fstVarWeights2 <- sapply(names(fstAllResults2)[1:5], function(x) sum(fstAllResults2$weight[fstAllResults2[, x]])/nBoots)


fstModelWeights2 <- fstAllResults2 %>%
                  group_by(predictors) %>%
                  summarise(AICc = mean(AIC)) %>%
                  mutate(dAIC = AICc - min(AICc), modelWeight = exp(- 0.5 * dAIC) / sum(exp(- 0.5 * dAIC))) %>%
                  arrange(desc(modelWeight)) %>%
                  mutate(cumulativeWeight = cumsum(modelWeight)) 





%%end.rcode

