%--------------------------------------------------------------------------------------------------------------------------------%
% Code for "Appendix B: A comparative test of the role of population structure in determining pathogen richness"
% Appendix for Chapter 3 of thesis "The role of population structure and size in determining bat pathogen richness"
% by Tim CD Lucas
%
% NB The file is numbered Appendix3 as Chapter 2 was previously Chapter 3 in the thesis.
%
%---------------------------------------------------------------------------------------------------------------------------------%







%%begin.rcode settings, echo = FALSE, cache = FALSE, message = FALSE, results = 'hide', eval = TRUE

# There are figures created in the data analysis which are not in the final chapter document.
#   If TRUE, they will be included in the output.
#   Use 'hide' to remove them.
extraFigs <- 'hide'

#knitr options
#  Set figure prefix as A so that no figures will be overwritten.
opts_chunk$set(cache.path = '.AppCh3Cache/', fig.path = 'figure/A-')
source('misc/KnitrOptions.R')

# ggplot2 theme.
source('misc/theme_tcdl.R')
theme_set(theme_grey() + theme_tcdl)


# Choose the number of cores to use
nCores <- 4

runScrape <- FALSE
rangeusesens <- FALSE
%%end.rcode


%%begin.rcode libs, cache = FALSE, result = FALSE

# Data handling
library(dplyr)
library(broom)
library(readxl)
library(sqldf)
library(reshape2)

# phylogenetic regression
library(ape)
library(caper)
library(phytools)
library(nlme)
library(qpcR)
library(car)

# weighted means + var
library(Hmisc)

# Plotting
library(ggplot2)
library(ggtree)
library(palettetown)
library(ggthemes)
library(GGally)
library(cowplot)

# tables
library(xtable)


# For synonym list
library(taxize)

# Spatial analysis
library(maptools)
library(geosphere)

# Parallel computation
library(parallel)

%%end.rcode


%%-------------------------------------------------------------------------------%%
%% Give full data tables for both analyses.
%%-------------------------------------------------------------------------------%%

%%begin.rcode parameters
nBoots <- 50

%%end.rcode


%%begin.rcode readRawData



fstFinal <- read.csv('data/Chapter3/fstFinal.csv', row.names = 1)

nSpecies <- read.csv('data/Chapter3/nSpecies.csv', row.names = 1)

%%end.rcode


%%begin.rcode rawDataTidy

# Join the data frames
joindf <- nSpecies %>%
            full_join(fstFinal)
            
# Hack a  variable to sort so that it's FST only, both, subspecies only.
joindf$whichAnalyses <- as.numeric(is.na(joindf$NumberOfSubspecies))
joindf$whichAnalyses[!is.na(joindf$NumberOfSubspecies) & !is.na(joindf$Nm)] <- 2
joindf$whichAnalyses[joindf$whichAnalyses == 0] <- 3

# Make references cite
joindf$References <- as.character(joindf$References)
joindf$References[!is.na(joindf$References)] <- paste0('\\cite{', joindf$References[!is.na(joindf$References)], '}')

# Sort and select wanted column
#   Have to do loads of converting to characters and sprintf because of units row below.
joindf <- joindf %>%
            mutate(binomial = paste0('\\emph{', binomial, '}')) %>%
            mutate(distrSize = sprintf('%.2f', distrSize / 1e9)) %>%
            mutate(Nm = sprintf('%.2f', Nm)) %>%
            mutate(Nm = replace(Nm, Nm == 'NA', '')) %>%
            mutate(rangeWidth = sprintf('%.2f', rangeWidth)) %>%
            mutate(rangeWidth = replace(rangeWidth, rangeWidth == 'NA', '')) %>%
            arrange(whichAnalyses, Family, binomial) %>%
            dplyr::select(Family, binomial, virusSpecies, NumberOfSubspecies, Nm, mass, 
                   distrSize, scholarRefs, pubmedRefs, rangeWidth, Dmax..km., References)

# All a horrible hack now. 
#   Add end head to end...
joindf <- joindf %>%  
            rbind(c('', '', '', '', '', '(g)', '($\\times 10^{9}$km$^2$)', '', '', '(km)', '(km)', ''), .)

names(joindf) <- c('Family', 'Binomial', 'Virus Sp.', 'Subsp.', 'Gene Flow', 'Mass', 
                   'Range Size', 'Scholar', 'PubMed', 'Range Length', 'Dmax', 'Reference')



%%end.rcode


\begin{landscape}

%%begin.rcode rawDataTable, results = 'asis', cache = FALSE
rawDataCapt <- '
Raw data for both analyses.
Range Length is the distance between furthest apart points in the species range.
Dmax is the distance between furthest apart $F_{ST}$ sampling locations.
The references are for the $F_{ST}$ data only.
'
rawDataTitle <- '
Raw data for both analyses
'


addtorow          <- list()
addtorow$pos      <- list()
addtorow$pos[[1]] <- c(1)
addtorow$command  <- c(paste("\\midrule\n",
                             "\\endfirsthead \n",
                             "\\caption[]{", rawDataCapt, "}\\\\\n",
                             "\\toprule\n",
"Family & Binomial & Virus Sp. & Subsp. & Gene Flow & Mass & Range Size & Scholar & PubMed & Range Length & Dmax & Reference \\\\\n ",
"  &  &  &  &  & (g) & ($\\times 10^{9}$km$^2$) &  &  & (km) & (km) &  \\\\\n ",
                             "\\midrule \n",
                             "\\endhead \n", sep=""))



print(xtable(joindf, 
             digits = 2, 
             caption = c(rawDataCapt, rawDataTitle), 
             label = "A-rawData",
             align = c('l', '@{}l', 'l', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'l@{}')), 
      size = "tiny", #Change size; useful for bigger tables
      include.rownames = FALSE, #Don't print rownames
      include.colnames = TRUE,
      tabular.environment = 'longtable',
      sanitize.colnames.function = function(x){x},
      sanitize.text.function = function(x){x},
      caption.placement = "top", 
      hline.after = c(-1, nrow(joindf)), 
      booktabs = TRUE,
      add.to.row = addtorow,
      floating = FALSE
    )


%%end.rcode
\end{landscape}











%%-------------------------------------------------------------------------------%%
%% Some plots of the data
%%-------------------------------------------------------------------------------%%








%%begin.rcode treeRead

# Read in trees
t <- read.nexus('data/Chapter3/fritz2009geographical.tre')

# Select best supported tree
tr1 <- t[[1]]

# Make names match previous names
tr1$tip.label <- gsub('_', ' ', tr1$tip.label)

# Which tips are not needed
unneededTips <- tr1$tip.label[!(tr1$tip.label %in% nSpecies$binomial)]

# Prune tree down to only needed tips.
pruneTree <- drop.tip(tr1, unneededTips)

rm(t)


%%end.rcode

%%begin.rcode scholarVsPubmed

# Check how correlated pubmed and scholar are.  

compSubspecies <- comparative.data(data = nSpecies, phy = pruneTree, names.col = 'binomial')

citeCor <- pgls(log(scholarRefs, base = 10) ~ log(pubmedRefs + 1, base = 10), data = compSubspecies, lambda = 'ML')


citeCor2 <- summary(pgls(log(scholarRefs) ~ log(pubmedRefs + 1), data = compSubspecies, lambda = 'ML'))

virusLambda <- summary(pgls(virusSpecies ~ 1, data = compSubspecies, lambda = 'ML'))

%%end.rcode

%%begin.rcode scholarvspubmedCapt


refsCapt <- paste0("
  Logged number of references on Google Scholar and PubMed, with a fitted phylogenetic linear model. 
  Colours indicate family. 
  (pgls: $t$ = ",
  round(citeCor2$coefficients['log(pubmedRefs + 1)', 't value'], 2), 
  ", df = ",
  citeCor2$df[2], 
  ", $p < 10^{-5}$).")

%%end.rcode

%%begin.rcode scholarvspubmedPlot, fig.show = TRUE, fig.height = 5, out.width = '0.9\\textwidth', fig.cap = refsCapt, cache = FALSE

pp <- c(pokepal('oddish')[c(1,3,5,7,9,10)], pokepal('Carvanha')[c(2, 4, 13, 12, 9, 1)])


studyEffortCor <- summary(citeCor)
# And plot
ggplot(nSpecies, aes(y = scholarRefs, x = pubmedRefs + 1)) +
  geom_point(aes(colour = familyPlotCol), size = 1.3) +
  scale_x_log10() +
  scale_y_log10() +
  theme(legend.position = 'bottom') +
  labs(y = 'Scholar Refs', x = 'PubMed Refs', colour = 'Family') + 
  scale_colour_manual(values = pp[c(2, 5, 6, 7, 9, 10, 11)], guide = guide_legend(ncol = 2, title.position = 'top')) +
  geom_abline(intercept = coef(citeCor)[1], slope = coef(citeCor)[2], size = 1)


%%end.rcode

%%begin.rcode subsDataCapts
subsDataCapts <- c(
'Unlogged number of virus species against log mass with a non-phylogenetic linear model added. Points are significantly jittered to try and reveal the severe overplotting in the bottom left corner in particular.',
'Number of virus species against logged number of subspecies (not marginal) with a non-phylogenetic linear model added. Points are significantly jittered to try and reveal the severe overplotting in the bottom left corner in particular.', 
'Number of virus species against logged number of subspecies (not marginal) with a non-phylogenetic linear model added.', 
'Virus species against study effort (log pubmed references +1)')
%%end.rcode

%%begin.rcode subsDataviz, fig.show = extraFigs, fig.cap = subsDataCapts, cache = FALSE

# A number of exploratory plots

# Mass against viruses
ggplot(nSpecies, aes(log(mass), virusSpecies)) +
  geom_point(aes(colour = familyPlotCol), size = 2.5) + 
  geom_smooth(method = 'lm')+
  labs(colour = 'Family') +
  scale_colour_hc()


# N Subspecies and against viruses
ggplot(nSpecies, aes(NumberOfSubspecies, virusSpecies)) +
  geom_jitter(aes(colour = familyPlotCol), size = 2.5, 
    position = position_jitter(width = .3, height = .3)) + 
  geom_smooth(method = 'lm')+
  labs(colour = 'Family') +
  scale_colour_hc()


# Log(N Subspecies) and against viruses

ggplot(nSpecies, aes(NumberOfSubspecies, virusSpecies)) +
  geom_jitter(aes(colour = familyPlotCol), size = 2.5, 
    position = position_jitter(width = .05, height = .2)) +
  scale_x_log10() + 
  geom_smooth(method = 'lm')+
  labs(colour = 'Family') +
  scale_colour_hc()


# N. Subspecies against viruses as a boxplot to deal with overplotting.
ggplot(nSpecies, aes(SubspeciesFactor, virusSpecies)) +
  geom_boxplot() +
  scale_x_discrete(limits = levels(nSpecies$SubspeciesFactor), drop=FALSE) +
  geom_smooth(method = 'lm', aes(group = 1)) +
  xlab('# subspecies')


# Study effort against virusSpecies
ggplot(nSpecies, aes(log(pubmedRefs + 1), virusSpecies)) +
  geom_jitter(aes(colour = familyPlotCol), size = 2.5, 
    position = position_jitter(width = .1, height = .1)) + 
  geom_smooth(method = 'lm') +
  labs(colour = 'Family')+
  scale_colour_hc()


# Distribution size aginst virus


ggplot(nSpecies, aes(distrSize, virusSpecies)) +
  geom_point(aes(colour = familyPlotCol), size = 2.5) + 
  geom_smooth(method = 'lm') +
  labs(colour = 'Family') +
  scale_colour_hc() +
  scale_x_log10()


# Correlation plot
nSpecies %>%
  dplyr::select(virusSpecies, NumberOfSubspecies, mass, distrSize, pubmedRefs, scholarRefs) %>%
  mutate(mass = log(mass), distrSize = log(distrSize), pubmedRefs = log(pubmedRefs + 1), scholarRefs = log(scholarRefs)) %>%
  ggpairs(.)

%%end.rcode













%%-------------------------------------------------------------------------------%%
%% Read full model selection results for both analyses and make tables.
%%-------------------------------------------------------------------------------%%




%%begin.rcode analyseModelSelect, fig.show = extraFigs

allResults <- read.csv('data/Chapter3/modelSelectSubspecies.csv', row.names = 1)

modelWeights <- allResults %>%
                  group_by(predictors) %>%
                  summarise(AICc = mean(AIC)) %>%
                  mutate(dAIC = AICc - min(AICc), modelWeight = exp(- 0.5 * dAIC) / sum(exp(- 0.5 * dAIC))) %>%
                  arrange(desc(modelWeight)) %>%
                  mutate(cumulativeWeight = cumsum(modelWeight)) %>%
                  mutate(predictors = gsub(':', '*', predictors)) %>%
                  mutate(predictors = gsub('scholarRefs', 'log(Scholar)', predictors)) %>%
                  mutate(predictors = gsub('mass', 'log(Mass)', predictors)) %>%
                  mutate(predictors = gsub('distrSize', 'log(RangeSize)', predictors)) %>%
                  mutate(predictors = gsub('1', 'Intercept only', predictors)) %>%
                  mutate(predictors = gsub('NumberOfSubspecies', 'NSubspecies', predictors))

colnames(modelWeights) <- c("Model", "$\\bar{\\text{AICc}}$", "$\\Delta$AICc", "$w$", "$\\sum w$") 

%%end.rcode



%%begin.rcode fstAnalyseModelSelect, fig.show = extraFigs


fstAllResults <- read.csv('data/Chapter3/fstModelSelectSubspecies.csv', row.names = 1)


fstModelWeights <- fstAllResults %>%
                  group_by(predictors) %>%
                  summarise(AICc = mean(AIC)) %>%
                  mutate(dAIC = AICc - min(AICc), modelWeight = exp(- 0.5 * dAIC) / sum(exp(- 0.5 * dAIC))) %>%
                  arrange(desc(modelWeight)) %>%
                  mutate(cumulativeWeight = cumsum(modelWeight)) %>%
                  mutate(predictors = gsub(':', '*', predictors)) %>%
                  mutate(predictors = gsub('scholarRefs', 'log(Scholar)', predictors)) %>%
                  mutate(predictors = gsub('mass', 'log(Mass)', predictors)) %>%
                  mutate(predictors = gsub('distrSize', 'log(RangeSize)', predictors)) %>%
                  mutate(predictors = gsub('1', 'Intercept only', predictors)) %>%
                  mutate(predictors = gsub('Nm', 'Gene Flow', predictors))

colnames(fstModelWeights) <- c("Model", "$\\bar{\\text{AICc}}$", "$\\Delta$AICc", "$w$", "$\\sum w$") 


%%end.rcode




%%begin.rcode printmodelweights, results = 'asis'

modelSelectCapt <- "
  Model selection results for number of subspecies analysis. 
  $\\bar{\\text{AICc}}$ is the mean AICc score across 50 resamplings of the null random variable. 
  $\\Delta$AICc is the model's $\\bar{\\text{AICc}}$ score minus $\\text{min}(\\bar{\\text{AICc}})$. 
  $w$ is the Akaike weight and can be interpreted as the probability that the model is the best model (of those in the plausible set).
  $\\sum w$ is the cumulative sum of the Akaike weights.
  log(Scholar)*NSubspecies implies the interaction term between study effort and number of subspecies.
  "

modelSelectTitle <- "
  Full model selection results for number of subspecies analysis
"

# floating.environment = 'sidewaystable') ? possible to do upright caption.
print(xtable(modelWeights, 
             digits = 2, 
             caption = c(modelSelectCapt, modelSelectTitle), 
             label = "A-modelWeights",
             align = c('l', '@{}l', 'r', 'r', 'r', 'r@{}')), 
      size = "tiny", #Change size; useful for bigger tables
      include.rownames = FALSE, #Don't print rownames
      include.colnames = TRUE,

      sanitize.colnames.function = function(x){x},
      caption.placement = "top", 
      hline.after = c(-1, 0, nrow(modelWeights)), 
      booktabs = TRUE
    )




%%end.rcode



%%begin.rcode printfsttable, results = 'asis'

fstSelectCapt <- "
  Model selection results for effective gene flow analysis. 
  $\\bar{\\text{AICc}}$ is the mean AICc score across 50 resamplings of the null random variable. 
  $\\Delta$AICc is the model's $\\bar{\\text{AICc}}$ score minus $\\text{min}(\\bar{\\text{AICc}})$. 
  $w$ is the Akaike weight and can be interpreted as the probability that the model is the best model (of those in the plausible set).
  $\\sum w$ is the cumulative sum of the Akaike weights.
  " 

fstSelectTitle <- "
  Full model selection results for effective gene flow analysis
"

print(xtable(fstModelWeights, 
             digits = 2, 
             caption = c(fstSelectCapt, fstSelectTitle),
             label = "A-fstModelWeights",
             align = c('l', '@{}l', 'r', 'r', 'r', 'r@{}')),  
      size = "scriptsize", #Change size; useful for bigger tables
      include.rownames = FALSE, #Don't print rownames
      include.colnames = TRUE,
      sanitize.colnames.function = function(x){x},
      caption.placement = "top", 
      hline.after = c(-1, 0, nrow(fstModelWeights)), 
      booktabs = TRUE
    )

%%end.rcode




%% ------------------------------------------------------------------------ %%
%% Examine interaction better.
%% ------------------------------------------------------------------------ %%


%%begin.rcode interactionPlot


effortRange <- c(quantile(scale(log(nSpecies$scholarRefs)), probs = c(0.25, 0.5, 0.75)), range(scale(log(nSpecies$scholarRefs))))

betasubspecies <- wtd.mean(allResults$beta.NumberOfSubspecies, allResults$weight, na.rm = TRUE) + 
								 			    	effortRange * wtd.mean(allResults$beta.scholarRefs.NumberOfSubspecies, 
									   														   allResults$weight, na.rm = TRUE)

intercept <-  wtd.mean(allResults$beta..Intercept., allResults$weight, na.rm = TRUE) + 
								wtd.mean(allResults$beta.scholarRefs, allResults$weight, na.rm = TRUE) * effortRange

# As all variables are scaled, mean is 0. So don't need to include other variables +
#								wtd.mean(allResults$beta.mass, allResults$weight, na.rm = TRUE) * median(log(nSpecies$mass)) +								
#								wtd.mean(allResults$beta.distrSize, allResults$weight, na.rm = TRUE) * median(log(nSpecies$distrSize)) #+								
#								wtd.mean(allResults$beta.rand, allResults$weight, na.rm = TRUE) * 0.5				


lines.df <- data.frame(y1 = 1 * betasubspecies + intercept,
											 y2 = 16 * betasubspecies + intercept,
											 x1 = 1,
											 x2 = 16,
											 type = factor(c(2, 1, 2, 3, 3)))

%%end.rcode


%%begin.rcode boxplotCapt	
		
# Caption for the main boxplot of subspecies vs virus		
		
boxplotCapt <- 
'The effect of the interaction term on the estimated relationship between number of subspecies and pathogen richness.
The area of the circle shows the number of bat species at each discrete value.
The black line shows the estimated regression slope at the median value of study effort while the blue and yellow lines show the estimated slope at the upper and lower quartiles and maximum and minimum values of study effort respectively.
'


boxplotTitle <- 'The effect of the interaction term on the estimated relationship between number of subspecies and pathogen richness'

%%end.rcode		
		
%%begin.rcode plotInter, fig.cap = boxplotCapt, fig.scap = boxplotTitle,	fig.height = 2.3


nSpeciesCounts <- nSpecies %>%
                    group_by(NumberOfSubspecies, virusSpecies) %>%
                    dplyr::summarize(n = n())

ggplot(nSpeciesCounts, aes(NumberOfSubspecies, virusSpecies, size = n)) + 
  geom_point() +
  scale_size(range = c(0.5, 4.3), breaks = c(1, 20, 40)) +
  scale_x_continuous(breaks = c(1,  4, 8, 12, 16)) +
  xlab('Number of Subspecies') +
  ylab('Viral Richness') +
  geom_segment(data = lines.df, 
							 aes(y = y1, yend = y2, x = x1, xend = x2, size = NULL, colour = type)) +
	scale_colour_manual(values = pokepal('exploud', spread = 3)[c(2, 1, 3)], guide = 'none') +
  guides(size = guide_legend(override.aes = list(linetype = 0)))


%%end.rcode	




%%-------------------------------------------------------------------------------%%
%% Read and plot bat clocks rocks tree.
%%-------------------------------------------------------------------------------%%


%%begin.rcode treeRead2

# Read in trees
t2 <- read.nexus('data/Chapter3/BatST2BL.nex')

# Make names match previous names
t2$tip.label <- gsub('_', ' ', t2$tip.label)

#missing <- nSpecies$binomial[!nSpecies$binomial %in% pruneTree2$tip.label ]

## Copy binomial column. binomial will be changed to fit t2.
#nSpecies$oldBinomial <- nSpecies$binomial

## Replace with agrep where possible
#closeMatch <- sapply(missing, function(i) t2$tip.label[agrep(i, t2$tip.label, max.distance = 0.11)])

#closeMatch <- closeMatch[sapply(closeMatch, function(i) length(i) > 0)]




unneededTips2 <- t2$tip.label[!(t2$tip.label %in% nSpecies$binomial)]

# Prune tree down to only needed tips.
pruneTree2 <- drop.tip(t2, unneededTips2)


nSpecies2 <- sapply(pruneTree2$tip.label, function(x) which(nSpecies$binomial == x)) %>%
               nSpecies[., ]


################
## Fst tree   ##
################


# Which tips are not needed
fstUnneededTips2 <- t2$tip.label[!(t2$tip.label %in% fstFinal$binomial)]

# Prune tree down to only needed tips.
fstTree2 <- drop.tip(t2, fstUnneededTips2)

# Which tips in Fst analysis are not in bats clocks tree.
fstFinal$binomial[!(fstFinal$binomial %in% fstTree2$tip.label)]


# Hacky cruddy way of placing the missing tips into the tree. Should end up with genus level polytomies in trimmed tree.
# Just replacing some of the uneeded tips with the ones I need.

t2$tip.label[t2$tip.label == 'Miniopterus pusillus'] <- 'Miniopterus natalensis'
t2$tip.label[t2$tip.label == 'Miniopterus schreibersi'] <- 'Miniopterus schreibersii'
t2$tip.label[t2$tip.label == 'Rousettus celebensis'] <- 'Rousettus leschenaultii'
t2$tip.label[t2$tip.label == 'Myotis oxyotus'] <- 'Myotis macropus'
t2$tip.label[t2$tip.label == 'Myotis leibii'] <- 'Myotis ciliolabrum'

#Re prune tree
# Which tips are not needed
fstUnneededTips2 <- t2$tip.label[!(t2$tip.label %in% fstFinal$binomial)]

# Prune tree down to only needed tips.
fstTree2 <- drop.tip(t2, fstUnneededTips2)

# Check we now have all the tips.
fstFinal$binomial[!(fstFinal$binomial %in% fstTree2$tip.label)]

rm(t2)




%%end.rcode



%%begin.rcode treeCapt


treeCapt <- '
The distribution of viral richness on the alternate phylogeny.
The phylogeny is from \\textcite{jones2005bats} (version 2) pruned to include all species used in either the number of subspecies or gene flow analysis.
Dot size shows the number of known viruses for that species and colour shows family.
The red scale bar shows 25 million years.'


treeTitle <- 'Pruned alternative phylogeny showing number of pathogens and family'

%%end.rcode


%%begin.rcode treePlot2, out.width = '1\\textwidth', out.extra = 'trim = 0cm 0cm 0cm 0cm', fig.height = 5, fig.height = 5.5, fig.cap = treeCapt, fig.scap = treeTitle, cache = FALSE

# Plot tree 
p <- ggtree(pruneTree2, layout = 'fan') 

p %<+% nSpecies +
  geom_point2(aes(size = virusSpecies, colour = Family, subset = isTip)) +
  scale_size(range = c(0.1, 3)) +
  scale_colour_manual(values = c(pokepal('oddish')[c(1,3,5,7,9,10)],    pokepal('Carvanha')[c(2,4, 13, 12, 9, 1)])) +
  theme_tcdl +
  theme(plot.margin = unit(c(-2, -0, +3, -0), "lines")) +
  theme(legend.position = c(0.5, -0.04)) +
#  guides(size = guide_legend(override.aes = list(shape = 1))) +
  geom_treescale(x = 0, y = 152, width = 25, color = pokepal(17)[3], offset = 9) +
  labs(size = 'Virus Richness') +
  theme(legend.key.size = unit(0.8, "lines"),
        legend.text = element_text(size = 10),
        legend.margin = unit(c(0.05), "cm"),
        legend.title = element_text(size = 12),
        legend.direction = "horizontal") +
  guides(colour = guide_legend(ncol=3))   


%%end.rcode







\begin{figure}[t]
\centering
  \includegraphics[width=1\textwidth]{figure/fstITPlots2-1.pdf}
  \caption[The relative weight of evidence that each explanatory variable is in the best model for explaining viral richness using alternative phylogeny]{
The relative weight of evidence that each explanatory variable is in the best model for explaining viral richness using the phylogeny from \cite{jones2005bats}.
The probability that each variable is in the best model (amongst the models tested) is shown for A) the number of subspecies analysis and B) the effective gene flow analysis.
The boxplots show the variation of the results over 50 resamplings of the uniformly random ``null'' variable. 
The thick bar of the boxplot shows the median value, the interquartile range is represented by a box, vertical lines represent range, and outliers are shown as filled circles.
The red ``Random'' box is the uniformly random variable. 
Population structure (number of subspecies and effective gene flow), shown in yellow, is likely to be in the best model in both analyses.
}
\label{f:A-itplots}
\end{figure}




%%begin.rcode batClocksAnalyse, echo = FALSE


allResults2 <- read.csv('data/Chapter3/modelSelectSubspeciesBatClocks.csv', row.names = 1)

varWeights2 <- sapply(names(allResults2)[1:6], function(x) sum(allResults2$weight[allResults2[, x]])/nBoots)


sepVarWeights2 <- lapply(1:nBoots, function(b) 
                      sapply(names(allResults2)[1:6], 
                        function(x) 
                          sum(allResults2[allResults2$boot == b, 'weight'][allResults2[allResults2$boot == b, x]])
                      )
                     )      

sepVarWeights2 <- do.call(rbind, sepVarWeights2) %>%
                      data.frame(., boot = 1:nBoots) %>%
                      reshape2::melt(., value.name = 'estimate', id.vars = 'boot')

sepVarWeights2$col <- 'Other Variables'
sepVarWeights2$col[grep('NumberOf', sepVarWeights2$variable)] <- 'Population Structure'
sepVarWeights2$col[sepVarWeights2$variable == 'rand'] <- 'Null'



modelWeights2 <- allResults2 %>%
                  group_by(predictors) %>%
                  summarise(AICc = mean(AIC)) %>%
                  mutate(dAIC = AICc - min(AICc), modelWeight = exp(- 0.5 * dAIC) / sum(exp(- 0.5 * dAIC))) %>%
                  arrange(desc(modelWeight)) %>%
                  mutate(cumulativeWeight = cumsum(modelWeight)) %>%
                  mutate(string = levels(predictors)[predictors])



varWeights2 <- sapply(names(allResults2)[1:6], 
  function(x) sum(modelWeights2$modelWeight[grep(x, as.character(modelWeights2$predictors))]))


coefMeans2 <- apply(allResults2[, grep('beta', names(allResults2))], 2, function(x) wtd.mean(x, allResults2$weight, na.rm = TRUE))



varCoefMeans2 <- apply(allResults[, grep('beta', names(allResults2))], 2, function(x) wtd.mean(x, allResults2$weight, na.rm = TRUE))
varCoefVars2  <- apply(allResults[, grep('beta', names(allResults2))], 2, function(x) wtd.var(x, allResults2$weight, na.rm = TRUE))

nSpeciesCoefMean2 <- wtd.mean(allResults2$beta.NumberOfSubspecies[!allResults2$scholarRefs.NumberOfSubspecies], 
                             allResults2$weight[!allResults2$scholarRefs.NumberOfSubspecies], na.rm = TRUE)
nSpeciesCoefMeanI2 <- wtd.mean(allResults2$beta.NumberOfSubspecies[allResults2$scholarRefs.NumberOfSubspecies], 
                             allResults2$weight[allResults2$scholarRefs.NumberOfSubspecies], na.rm = TRUE)
nSpeciesInterMean2 <- wtd.mean(allResults2$`beta.scholarRefs.NumberOfSubspecies`, allResults2$weight, na.rm = TRUE)


#### FST


fstAllResults2 <- read.csv('data/Chapter3/fstModelSelectSubspeciesBatClocks.csv', row.names = 1)

fstSepVarWeights2 <- lapply(1:nBoots, function(b) 
                      sapply(names(fstAllResults2)[1:5], 
                        function(x) 
                          sum(fstAllResults2[fstAllResults2$boot == b, 'weight'][fstAllResults2[fstAllResults2$boot == b, x]])
                      )
                     )      

fstSepVarWeights2 <- do.call(rbind, fstSepVarWeights2) %>%
                      data.frame(., boot = 1:nBoots) %>%
                      reshape2::melt(., value.name = 'estimate', id.vars = 'boot')

fstSepVarWeights2$col <- 'Other Variables'
fstSepVarWeights2$col[fstSepVarWeights2$variable == 'Nm'] <- 'Population Structure'
fstSepVarWeights2$col[fstSepVarWeights2$variable == 'rand'] <- 'Null'


#fstVarWeights2 <- sapply(names(fstAllResults2)[1:5], function(x) sum(fstAllResults2$weight[fstAllResults2[, x]])/nBoots)


fstModelWeights2 <- fstAllResults2 %>%
                  group_by(predictors) %>%
                  summarise(AICc = mean(AIC)) %>%
                  mutate(dAIC = AICc - min(AICc), modelWeight = exp(- 0.5 * dAIC) / sum(exp(- 0.5 * dAIC))) %>%
                  arrange(desc(modelWeight)) %>%
                  mutate(cumulativeWeight = cumsum(modelWeight)) 

fstVarWeights2 <- sapply(names(fstAllResults2)[1:5], 
  function(x) sum(fstModelWeights2$modelWeight[grep(x, as.character(fstModelWeights2$predictors))]))


fstCoefMeans2 <- apply(fstAllResults2[, grep('beta', names(fstAllResults2))], 2, function(x) wtd.mean(x, fstAllResults2$weight, na.rm = TRUE))


%%end.rcode





%%begin.rcode analyseModelSelect2, fig.show = extraFigs

modelWeightsFull2 <- allResults2 %>%
                  group_by(predictors) %>%
                  summarise(AICc = mean(AIC)) %>%
                  mutate(dAIC = AICc - min(AICc), modelWeight = exp(- 0.5 * dAIC) / sum(exp(- 0.5 * dAIC))) %>%
                  arrange(desc(modelWeight)) %>%
                  mutate(cumulativeWeight = cumsum(modelWeight)) %>%
                  mutate(predictors = gsub(':', '*', predictors)) %>%
                  mutate(predictors = gsub('scholarRefs', 'log(Scholar)', predictors)) %>%
                  mutate(predictors = gsub('mass', 'log(Mass)', predictors)) %>%
                  mutate(predictors = gsub('distrSize', 'log(RangeSize)', predictors)) %>%
                  mutate(predictors = gsub('1', 'Intercept only', predictors)) %>%
                  mutate(predictors = gsub('NumberOfSubspecies', 'NSubspecies', predictors))

colnames(modelWeightsFull2) <- c("Model", "$\\bar{\\text{AICc}}$", "$\\Delta$AICc", "$w$", "$\\sum w$") 

%%end.rcode



%%begin.rcode fstAnalyseModelSelect2, fig.show = extraFigs

fstModelWeightsFull2 <- fstAllResults2 %>%
                  group_by(predictors) %>%
                  summarise(AICc = mean(AIC)) %>%
                  mutate(dAIC = AICc - min(AICc), modelWeight = exp(- 0.5 * dAIC) / sum(exp(- 0.5 * dAIC))) %>%
                  arrange(desc(modelWeight)) %>%
                  mutate(cumulativeWeight = cumsum(modelWeight)) %>%
                  mutate(predictors = gsub(':', '*', predictors)) %>%
                  mutate(predictors = gsub('scholarRefs', 'log(Scholar)', predictors)) %>%
                  mutate(predictors = gsub('mass', 'log(Mass)', predictors)) %>%
                  mutate(predictors = gsub('distrSize', 'log(RangeSize)', predictors)) %>%
                  mutate(predictors = gsub('1', 'Intercept only', predictors)) %>%
                  mutate(predictors = gsub('Nm', 'Gene Flow', predictors))

colnames(fstModelWeightsFull2) <- c("Model", "$\\bar{\\text{AICc}}$", "$\\Delta$AICc", "$w$", "$\\sum w$") 


%%end.rcode




%%begin.rcode printmodelweights2, results = 'asis'


modelSelectCapt <- "
  Model selection results for number of subspecies analysis using phylogeny from \\cite{jones2005bats}. 
  $\\bar{\\text{AICc}}$ is the mean AICc score across 50 resamplings of the null random variable. 
  $\\Delta$AICc is the model's $\\bar{\\text{AICc}}$ score minus $\\text{min}(\\bar{\\text{AICc}})$. 
  $w$ is the Akaike weight and can be interpreted as the probability that the model is the best model (of those in the plausible set).
  $\\sum w$ is the cumulative sum of the Akaike weights.
  log(Scholar)*NSubspecies implies the interaction term between study effort and number of subspecies.
  "

modelSelectTitle <- "
  Full model selection results for number of subspecies analysis using alternative phylogeny
"

# floating.environment = 'sidewaystable') ? possible to do upright caption.
print(xtable(modelWeightsFull2, 
             digits = 2, 
             caption = c(modelSelectCapt, modelSelectTitle), 
             label = "A-modelWeights2",
             align = c('l', '@{}l', 'r', 'r', 'r', 'r@{}')), 
      size = "tiny", #Change size; useful for bigger tables
      include.rownames = FALSE, #Don't print rownames
      include.colnames = TRUE,

      sanitize.colnames.function = function(x){x},
      caption.placement = "top", 
      hline.after = c(-1, 0, nrow(modelWeightsFull2)), 
      booktabs = TRUE
    )




%%end.rcode



%%begin.rcode printfsttable2, results = 'asis'


fstSelectCapt <- "
  Model selection results for effective gene flow analysis using phylogeny from \\cite{jones2005bats}. 
  $\\bar{\\text{AICc}}$ is the mean AICc score across 50 resamplings of the null random variable. 
  $\\Delta$AICc is the model's $\\bar{\\text{AICc}}$ score minus $\\text{min}(\\bar{\\text{AICc}})$. 
  $w$ is the Akaike weight and can be interpreted as the probability that the model is the best model (of those in the plausible set).
  $\\sum w$ is the cumulative sum of the Akaike weights.
  "

fstSelectTitle <- "
  Full model selection results for effective gene flow analysis with alternative phylogeny 
"

print(xtable(fstModelWeightsFull2, 
             digits = 2, 
             caption = c(fstSelectCapt, fstSelectTitle),
             label = "A-fstModelWeights2",
             align = c('l', '@{}l', 'r', 'r', 'r', 'r@{}')),  
      size = "scriptsize", #Change size; useful for bigger tables
      include.rownames = FALSE, #Don't print rownames
      include.colnames = TRUE,
      sanitize.colnames.function = function(x){x},
      caption.placement = "top", 
      hline.after = c(-1, 0, nrow(fstModelWeightsFull2)), 
      booktabs = TRUE
    )


%%end.rcode








\begin{table}[t]
\centering
\caption[Estimated variable weights and coefficients using alternative phylogeny]{
Estimated variable weights (probability that a variable is in the best model) and their estimated coefficients for both number of subspecies and gene flow analyses using phylogeny from \cite{jones2005bats}.
The coefficients for the number of subspecies variable are also separated for models with and without the interaction term because this term strongly changes the coefficient and because the coefficient can only be usefully interpreted when estimated without the interaction. 
However, there are no weights for these separated terms as they are not directly compared in the model selection framework.
}
%\rowcolors{2}{gray!25}{white}
\begin{tabular}{@{}>{\small}l rrrr@{}}
\toprule
& \multicolumn{2}{c}{\textit{Number of Subspecies}} & \multicolumn{2}{c}{\textit{Gene flow}}\\\cmidrule(rl){2-3}\cmidrule(rl){4-5}
\normalsize{Variable} & $Pr$ & Coefficient & $Pr$ & Coefficient\\
\midrule
Number of subspecies &&&&\\
\hspace{3mm}Total & \rinline{sprintf('%.2f', varWeights2['NumberOfSubspecies'])} & \rinline{varCoefMeans2['beta.NumberOfSubspecies']} &&\\
\hspace{3mm}Models without interaction term &&  \rinline{nSpeciesCoefMean2} &&\\
\hspace{3mm}Models with interaction term &&  \rinline{nSpeciesCoefMeanI2} &&\\
Number of subspecies*log(Scholar) &  \rinline{varWeights2['scholarRefs.NumberOfSubspecies']} &  \rinline{sprintf('%.2f', varCoefMeans2['beta.scholarRefs.NumberOfSubspecies'])} && \\[2.5mm]  
Gene flow & & &  \rinline{sprintf('%.2f', fstVarWeights2['Nm'])} &  \rinline{fstCoefMeans2['beta.Nm']}\\[2.5mm]  
log(Scholar) &  \rinline{sprintf('%.2f', varWeights2['scholarRefs'])} &  \rinline{varCoefMeans2['beta.scholarRefs']} & 
   \rinline{sprintf('%.2f', fstVarWeights2['scholarRefs'])} &  \rinline{fstCoefMeans2['beta.scholarRefs']}\\
log(Mass) &  \rinline{sprintf('%.2f', varWeights2['mass'])} &  \rinline{varCoefMeans2['beta.mass']} & 
   \rinline{sprintf('%.2f', fstVarWeights2['mass'])} &  \rinline{fstCoefMeans2['beta.mass']}\\
log(Range size) &  \rinline{sprintf('%.2f', varWeights2['distrSize'])} &  \rinline{varCoefMeans2['beta.distrSize']}& 
   \rinline{sprintf('%.2f', fstVarWeights2['distrSize'])} &  \rinline{fstCoefMeans2['beta.distrSize']}\\
Random &  \rinline{sprintf('%.2f', varWeights2['rand'])} &  \rinline{sprintf('%.2f', varCoefMeans2['beta.rand'])}& 
   \rinline{sprintf('%.2f', fstVarWeights2['rand'])} &  \rinline{fstCoefMeans2['beta.rand']}\\
\bottomrule
\end{tabular}

\label{t:variables2}
\end{table}






























% ------------------------------------------------------------------------ %
%% Bootstrap rangeuseable parameter
% ------------------------------------------------------------------------ %


%%begin.rcode scholarScrapeFunc

scrapeScholar <- function(sp){
    
  wait <- rnorm(1, 320, 2)
  Sys.sleep(wait)


  syns <- synonyms(sp, db = 'itis')
  if(NROW(syns[[1]]) == 1){
    spString <- tolower(gsub(' ', '%20', sp))
  } else {
    spString <- paste(tolower(gsub(' ', '%20', syns[[1]]$syn_name)), collapse = '%22+OR+%22')
  }

  url <- paste0('https://scholar.google.co.uk/scholar?hl=en&q=%22', 
                spString, '%22&btnG=&as_sdt=1%2C5&as_sdtp=')


  page <- html(url)
  
  try({
  refs <- page %>%
            html_node('#gs_ab_md') %>%
            html_text() %>%
            gsub('About\\s(.*)\\sresults.*', '\\1', .) %>%
            gsub(',', '', .) %>%
            as.numeric
  })
  return(refs)
}

%%end.rcode






%%begin.rcode luis2013virusRead, eval = rangeusesens

#read in luis2013virus data
virus2 <- read.csv('data/Chapter3/luis2013comparison.csv', stringsAsFactors = FALSE)


virus2$binomial <- paste(virus2$host.genus, virus2$host.species)


# From methods
#Many viruses were not identified to species level or their identified species was not in the ICTV virus taxonomy \cite{ICTV}.
#I counted a virus if it was the only virus, for that host species, in the lowest taxonomic level identified in the ICTV taxonomy.
#That is, if a host carries an unknown Paramyxoviridae virus, then it must carry at least one Paramyxoviridae virus.
#If a host carries an unknown Paramyxoviridae virus and a known Paramyxoviridae virus, then it is hard to confirm that the unknown virus is not another record of the known virus.
#In this case, this would be counted as one virus species.

# This has been implemented manually and indicated in the column `remove`

virus2 <- virus2[!virus2$remove, ]

%%end.rcode

%%begin.rcode ranges, eval = rangeusesens

# Read in iucn ranges and calculate range sizes for each species.
ranges <- readShapePoly('data/Chapter3/TERRESTRIAL_MAMMALS/TERRESTRIAL_MAMMALS.shp')

ranges <- ranges[ranges$order_name == 'CHIROPTERA', ]

levels(ranges$binomial) <- c(levels(ranges$binomial), 'Myotis ricketti')
ranges$binomial[ranges$binomial == 'Myotis pilosus'] <- 'Myotis ricketti'


%%end.rcode



%%begin.rcode fstRead, eval = rangeusesens

# Read in Fst data.
# Then add extra columns needed.

fst <- read.csv('data/Chapter3/FstDataCompData.csv')

# Check overlap of datasets.
sum(!(fst$binomial %in% virus2$binomial[virus2$host.species != '']))

notInFst <- fst$binomial[!(fst$binomial %in% virus2$binomial)]
# lots of sp not in virus2. MAybe will include 0 virus species. Kinda makes sense.



#########################################################################################
#### Get distribution size and width                                                 ####
#########################################################################################




fst$binomial[!(fst$binomial %in% ranges$binomial)]

fst <- fst[(fst$binomial %in% ranges$binomial), ]

unique(fst$binomial) %>% length




findAreaFst <- function(name){
  #cat(name)
  A <- areaPolygon(ranges[ranges$binomial == as.character(name), ])
  sum(A)
}

fstIucnDistr <- sapply(fst$binomial, findAreaFst)


fst$distrSize <- fstIucnDistr


#### Now get distribution width

findWidth <- function(name){
  #print(name)
  distr <- ranges[ranges$binomial == as.character(name), ]

  coords <- list()
  # Get coordinates from all polygons into one matrix.
  for(i in 1:length(distr@polygons)){
    coords[[i]] <- distr@polygons[[i]]@Polygons[[1]]@coords
  }
  coords <- do.call(rbind, coords)

  # Take the convex hull of coordinates to speed up last step.
  hullCoords <- coords[chull(coords), ]

  maxDist <- max(apply(hullCoords, 1, function(x) distGeo(coords, x)))/1000
  return(maxDist)
  
}

# Calculate widest part of all species distributions.
#   This is slow but also RAM heavy.
#   3 cores doesn't crash my computer with 16GB RAM.
rangeWidth <- mclapply(fst$binomial, findWidth, mc.cores = 3) %>% do.call(c, .)

#rangeWidth <- sapply(fst$binomial, findWidth)

fst$rangeWidth <- rangeWidth
fst$rangeCoverage <- fst$Dmax..km. / fst$rangeWidth





%%end.rcode



%%begin.rcode fstStudyEffort, eval = rangeusesens

nSpecies <- read.csv(file = 'data/Chapter3/nSpecies.csv')

# First take what data we can from nSpecies analysis.
fstStudy <- sqldf("	
                SELECT fst.binomial, nSpecies.scholarRefs, nSpecies.pubmedRefs
                FROM fst
                LEFT JOIN nSpecies
                ON nSpecies.binomial=fst.binomial
              ")

%%end.rcode




%%begin.rcode fstScrape, eval = runScrape

########################################################
#### Sloow bit that might get you blocked by google ####
########################################################

fstFullStudy <- fstStudy[,1:2]




for(i in 1:nrow(fstFullStudy)){
	if(is.na(fstFullStudy[i, 2])){
		fstFullStudy[i, 2] <- scrapeScholar(fstFullStudy[i, 1])
	}
	print(i)
}



write.csv(fstFullStudy, file = 'data/Chapter3/fstScrapeAppendix.csv')

%%end.rcode


%%begin.rcode readNewStudy, eval = rangeusesens

fstFullStudy <- read.csv(file = 'data/Chapter3/fstScrapeAppendix.csv')[, -1]

fst$scholarRefs <- fstFullStudy[, 2]



calcNm <- function(Fst){ (1 - Fst)/(4 * Fst) }


fst$Nm <- calcNm(fst$Value)



fst <- fst[!is.na(fst$Nm) & !(fst$Nm == Inf), ]
fst <- fst[fst$Marker != 'mtDNA', ]


# Couple of small cleaning issues.
# Two values for Miniopterus screibersii. One low range coverage, one big.
# Instead of taking means, remove the low coverage row.
# And similar issue with Myotis lucifugus
fst <- fst %>% filter(!(binomial == 'Miniopterus schreibersii' & rangeCoverage < 0.1))
fst <- fst %>% filter(!(binomial == 'Myotis lucifugus' & rangeCoverage < 0.2))


fstFinal <- fst


# Take means of species with multiple measurements

fstFinal <- fstFinal[!duplicated(fstFinal$binomial), ]
fstFinal$Nm <- sapply(fstFinal$binomial, function(x) mean(fst$Nm[fst$binomial == x]))

# Add number of viruses to fst dataset
#   Includes zeros for species with no known viruses.

fstFinal$virusSpecies <- sapply(fstFinal$binomial, function(x) sum(virus2$binomial == x))




# Add mass data.

pantheria <- read.table(file = 'data/Chapter3/PanTHERIA_1-0_WR05_Aug2008.txt',
  header = TRUE, sep = "\t", na.strings = c("-999", "-999.00"))

additionalMass <- read.csv('data/Chapter3/AdditionalBodyMass.csv', stringsAsFactors = FALSE)
meanAdditionalMass <- additionalMass %>%
                        group_by(binomial) %>% 
                        summarise(mass = mean(Body.Mass.grams))

mass <- sqldf("
  SELECT [X5.1_AdultBodyMass_g]
  FROM fstFinal
  LEFT JOIN pantheria
  ON fstFinal.binomial=pantheria.MSW05_Binomial
  ")

# Don't need pantheria data anymore
rm(pantheria)

fstFinal$mass <- mass[, 1]

fstFinal$mass[fstFinal$binomial == 'Myotis ricketti'] <- meanAdditionalMass$mass[meanAdditionalMass$binomial == 'Myotis ricketti']

fstFinal$mass[fstFinal$binomial == 'Myotis macropus'] <- 9.8



fstFinal <- fstFinal[!is.na(fstFinal$mass), ]


#############################
### fst data is finished  ###
#############################

write.csv(fstFinal, 'data/Chapter3/fstFinalBootRangeuseable.csv')

%%end.rcode






%%begin.rcode fstTree, eval = rangeusesens

# Read in trees
t <- read.nexus('data/Chapter3/fritz2009geographical.tre')

# Select best supported tree
tr1 <- t[[1]]

# Make names match previous names
tr1$tip.label <- gsub('_', ' ', tr1$tip.label)

#unneededTips <- tr1$tip.label[!(tr1$tip.label %in% fstFinal$binomial)]

# Prune tree down to only needed tips.
#fstTree <- drop.tip(tr1, unneededTips)



%%end.rcode


%%begin.rcode fstITanalysis, eval = rangeusesens

fstVarList <- c('scholarRefs', 'Nm', 'mass', 'distrSize', 'rand')

findCombs <- function(k, vars, longest){
  x <- t(combn(vars, k))
  nas <- matrix(NA, ncol = longest - NCOL(x), nrow = nrow(x))
  mat <- cbind(x, nas)
  return(mat)
}

fstModelList <- lapply(0:5, function(k) findCombs(k, fstVarList, 5))
fstModelMat <- do.call(rbind, fstModelList)

fstAllFormulae <- apply(fstModelMat[-1, ], 1, function(x) as.formula(paste('virusSpecies ~', paste(x[!is.na(x)], collapse = ' + '))))

fstAllFormulae <- c(as.formula('virusSpecies ~ 1'), fstAllFormulae)

%%end.rcode

%%begin.rcode fstModelSelectFun, eval = rangeusesens


fstModelSelect <- function(allForm, data, phy, boot, allModelMat, varList){
  
  set.seed(paste0('2388', boot))
  bootData <- cbind(data, rand = runif(nrow(data)))
  row.names(bootData) <- bootData$binomial

  
  # Prune the tree for the fst data.
  
  # Which tips are not needed
  fstUnneededTips <- tr1$tip.label[!(tr1$tip.label %in% data$binomial)]
  
  # Prune tree down to only needed tips.
  phy <- drop.tip(tr1, fstUnneededTips)



  # log some predictors
  bootData[, c('mass', 'scholarRefs', 'distrSize')] <- log(bootData[, c('mass', 'scholarRefs', 'distrSize')])
  
  # scale
  bootData[, c('mass', 'scholarRefs', 'distrSize', 'rand', 'Nm')] <- base::scale(bootData[, c('mass', 'scholarRefs', 'distrSize', 'rand', 'Nm')])
  

  coefs <- matrix(NA, ncol = length(varList) + 1, nrow = nrow(allModelMat), 
             dimnames = list(NULL, paste0('beta.', c('(Intercept)', varList))))

  results <- apply(allModelMat, 1, 
                   function(x) sapply(varList, function(y) y %in% x)) %>%
               t %>%
               data.frame %>%
               cbind(AIC = NA, 
                     boot = boot, 
                     lambda = NA, 
                     attempt = NA, 
                     predictors = NA, 
                     coefs)

  # Fit each model 
  # I'm having problems with convergence so sometimes have to try different starting values.
  # Really need to replace this with a while loop or something.
  for(m in 1:length(allForm)){
    if(exists('model')){
      rm(model)
    }
    try({
      model <- gls(allForm[[m]], correlation = corPagel(value = 0.4, phy = phy), data = bootData, method = 'ML')  
      results$attempt[m] <- 1
    }) 
    if(!exists('model')){
      try({
        model <- gls(allForm[[m]], correlation = corPagel(value = 0.3, phy = phy), data = bootData, method = 'ML')  
        results$attempt[m] <- 2
      }) 
    }
    if(!exists('model')){
      try({
        model <- gls(allForm[[m]], correlation = corPagel(value = 0.2, phy = phy), data = bootData, method = 'ML')  
        results$attempt[m] <- 3
      }) 
    }
    if(!exists('model')){
        try({
          model <- gls(allForm[[m]], correlation = corPagel(value = runif(1), phy = phy), data = bootData, method = 'ML')  
          results$attempt[m] <- 4
        }) 
      }
      if(!exists('model')){
        try({
          model <- gls(allForm[[m]], correlation = corPagel(value = runif(1), phy = phy), data = bootData, method = 'ML')  
          results$attempt[m] <- 5
        }) 
      }
      if(!exists('model')){
        try({
          model <- gls(allForm[[m]], correlation = corPagel(value = runif(1), phy = phy), data = bootData, method = 'ML')  
          results$attempt[m] <- 6
        }) 
      }
      if(!exists('model')){
        try({
          model <- gls(allForm[[m]], correlation = corPagel(value = runif(1), phy = phy), data = bootData, method = 'ML')  
          results$attempt[m] <- 7
        }) 
      }
       if(!exists('model')){
        try({
          model <- gls(allForm[[m]], correlation = corPagel(value = runif(1), phy = phy), data = bootData, method = 'ML')  
          results$attempt[m] <- 7
        }) 
      }
       if(!exists('model')){
        try({
          model <- gls(allForm[[m]], correlation = corPagel(value = runif(1), phy = phy), data = bootData, method = 'ML')  
          results$attempt[m] <- 7
        }) 
      }
       if(!exists('model')){
        try({
          model <- gls(allForm[[m]], correlation = corPagel(value = runif(1), phy = phy), data = bootData, method = 'ML')  
          results$attempt[m] <- 7
        }) 
      }
    if(!exists('model')){
      try({
        model <- lm(allForm[[m]], data = bootData) 
        results$attempt[m] <- 8
        message('Running lm')
      }) 
    }
    #model <- pgls(allForm[[m]], data = compBootData, lambda = 'ML')
    results$AIC[m] <- AICc(model)

    if(inherits(model, 'gls')){
        results$lambda[m] <- model$modelStruct$corStruct[1]
    }

    results$predictors[m] <- allForm[[m]] %>% as.character %>% .[3]


    results[m, paste0('beta.', names(coef(model)))] <- coef(model)

    message(paste('Boot:', boot, ', m:', m, '\n'))
  }

  results$dAIC <- results$AIC - min(results$AIC)
  results$weight <- exp(- 0.5 * results$dAIC) / sum(exp(- 0.5 * results$dAIC))


  return(results)

}

%%end.rcode

%%begin.rcode fstModelSelectBoots, eval = rangeusesens

rangeUseable <- c(0.15, 0.175, 0.2, 0.225, 0.25)



fstModelsBootStrap <- mclapply(1:nBoots, function(b) 
    fstModelSelect(fstAllFormulae, 
                   fstFinal[fstFinal$rangeCoverage > rangeUseable[1], ],
                   fstTree, 
                   b, 
                   fstModelMat, 
                   fstVarList), mc.cores = nCores)

fstAllResults1 <- do.call(rbind, fstModelsBootStrap)

write.csv(fstAllResults1, file = 'data/Chapter3/fstModelSelectBoot1.csv')


fstModelsBootStrap <- mclapply(1:nBoots, function(b) 
    fstModelSelect(fstAllFormulae, 
                   fstFinal[fstFinal$rangeCoverage > rangeUseable[2], ],
                   fstTree, 
                   b, 
                   fstModelMat, 
                   fstVarList), mc.cores = nCores)

fstAllResults2 <- do.call(rbind, fstModelsBootStrap)

write.csv(fstAllResults2, file = 'data/Chapter3/fstModelSelectBoot2.csv')


fstModelsBootStrap <- mclapply(1:nBoots, function(b) 
    fstModelSelect(fstAllFormulae, 
                   fstFinal[fstFinal$rangeCoverage > rangeUseable[3], ],
                   fstTree, 
                   b, 
                   fstModelMat, 
                   fstVarList), mc.cores = nCores)

fstAllResults3 <- do.call(rbind, fstModelsBootStrap)

write.csv(fstAllResults3, file = 'data/Chapter3/fstModelSelectBoot3.csv')


fstModelsBootStrap <- mclapply(1:nBoots, function(b) 
    fstModelSelect(fstAllFormulae, 
                   fstFinal[fstFinal$rangeCoverage > rangeUseable[4], ],
                   fstTree, 
                   b, 
                   fstModelMat, 
                   fstVarList), mc.cores = nCores)

fstAllResults4 <- do.call(rbind, fstModelsBootStrap)

write.csv(fstAllResults4, file = 'data/Chapter3/fstModelSelectBoot4.csv')


fstModelsBootStrap <- mclapply(1:nBoots, function(b) 
    fstModelSelect(fstAllFormulae, 
                   fstFinal[fstFinal$rangeCoverage > rangeUseable[5], ],
                   fstTree, 
                   b, 
                   fstModelMat, 
                   fstVarList), mc.cores = nCores)

fstAllResults5 <- do.call(rbind, fstModelsBootStrap)

write.csv(fstAllResults5, file = 'data/Chapter3/fstModelSelectBoot5.csv')

%%end.rcode


%%begin.rcode fstAnalyseModelSelectRangeUse, fig.show = extraFigs, eval = rangeusesens

#combAllResults <- list()
fstres <- list(fstAllResults, 
               fstAllResults1, 
               fstAllResults2, 
               fstAllResults3, 
               fstAllResults4,
               fstAllResults5)
               
               
for(i in 1:length(fstres)){
        
  fstSepVarWeights <- lapply(1:nBoots, function(b) 
                        sapply(names(fstres[[i]])[1:5], 
                          function(x) 
                            sum(fstres[[i]][fstres[[i]]$boot == b, 'weight'][fstres[[i]][fstres[[i]]$boot == b, x]])
                        )
                       )      
  
  fstSepVarWeights <- do.call(rbind, fstSepVarWeights) %>%
                        data.frame(., boot = 1:nBoots) %>%
                        reshape2::melt(., value.name = 'estimate', 
                                          id.vars = 'boot')
  
  fstSepVarWeights$col <- 'Other Variables'
  fstSepVarWeights$col[fstSepVarWeights$variable == 'Nm'] <- 'Population Structure'
  fstSepVarWeights$col[fstSepVarWeights$variable == 'rand'] <- 'Null'
  fstSepVarWeights$useableRange <- c(0.2, rangeUseable)[i]
  combAllResults[[i]] <- fstSepVarWeights
}


allCombinedResults.df <- do.call(rbind, combAllResults)

%%end.rcode



%%begin.rcode fstITBootCapt
ITPlotCapts <- ''
ITPlotTitle <- ''
%%end.rcode

%%begin.rcode fstITBootPlots, fig.cap = ITPlotCapts, fig.height = 2.5, fig.scap = ITPlotTitle, out.width = '\\textwidth', cache = FALSE, eval = rangeusesens

# Reorder var levels to get structure at beginning.
allCombinedResults.df$variable <- factor(allCombinedResults.df$variable, levels(allCombinedResults.df$variable)[c(2, 1, 3, 4, 5)])


# Draw the fst model selection plot
ggplot(allCombinedResults.df, aes(x = variable, y = estimate, colour = col, fill = col)) +
  geom_boxplot() +
  scale_colour_manual(values = pokepal('kingdra')[c(11, 1, 9)]) +
  scale_fill_manual(values = pokepal('kingdra')[c(12, 4, 8)]) +
  theme(legend.position = 'none', axis.text.x = element_text(size = 10, angle = 40, hjust = 1, colour = 'black', family = 'lato light'),
    panel.grid.major.x = element_blank(),
    axis.text.y = element_text(size = 8)) +
  scale_x_discrete(labels = c('Gene flow', 'Scholar', 'Mass', 'Range size', 'Random')) +
  scale_y_continuous(labels = c('0.00','0.25','0.50','0.75','1.00'), breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  ylab('P(in best model)') +
  xlab('')


%%end.rcode






